# Travis CI config for Snorkel, a training data creation and management
# system focused on information extraction

dist: trusty
sudo: false  # to use container-based infra, see: http://docs.travis-ci.com/user/migrating-from-legacy/

language:
  - python
python:
  - "2.7"
jdk:
  - oraclejdk8

cache:
  directories:
    - download
    - $HOME/.cache/pip
    - $HOME/miniconda/envs/test      # to avoid repetitively setting up Ana/Miniconda environment
    - parser                         # to avoid repetitively downloading CoreNLP

addons:
  apt:
    packages:
    # CoreNLP needs Java 8
    - oracle-java8-installer

# Following trick is necessary to get a binary distribution of numpy, scipy, etc. which takes too long to build every time
# See: http://stackoverflow.com/q/30588634
# See: https://github.com/Theano/Theano/blob/master/.travis.yml (for caching)
# See: http://conda.pydata.org/docs/travis.html
before_install:
  - deactivate  # leaving Travis' virtualenv first since otherwise Jupyter/IPython gets confused with conda inside a virtualenv (See: https://github.com/ipython/ipython/issues/8898)
  - mkdir -p download
  - cd download
  - travis_retry wget -c http://repo.continuum.io/miniconda/Miniconda-3.8.3-Linux-x86_64.sh -O miniconda.sh
  - chmod +x miniconda.sh
  - bash miniconda.sh -b -f -p ~/miniconda
  - cd ..
  - export PATH=~/miniconda/bin:$PATH
  - conda update --yes conda

  # Make sure Java 8 is used
  - export PATH="/usr/lib/jvm/java-8-oracle/bin:$PATH"
  - export JAVA_HOME=/usr/lib/jvm/java-8-oracle
  - java -version

  # Set environment variables
  - source set_env.sh

install:
  # Install binary distribution of scientific python modules
  - test -e ~/miniconda/envs/test/bin/activate || ( rm -rf ~/miniconda/envs/test; conda create --yes -n test python=$TRAVIS_PYTHON_VERSION )
  - source activate test
  - conda install --yes numpy scipy matplotlib pip

  # Install Numba
  - conda install --yes numba

  # Install all remaining dependencies as per our README
  - pip install -r python-package-requirement.txt
  - test -e parser/corenlp.sh || ./install-parser.sh

  # Use runipy to run Jupyter/IPython notebooks from command-line
  - pip install runipy

script:

  # Run test modules
  - python test/learning/test_gen_learning.py
  - python test/learning/test_supervised.py
  - python test/learning/test_categorical.py
  - runipy test/learning/test_TF_notebook.ipynb

  # Runs intro tutorial notebooks
  - cd tutorials
  - runipy intro/Intro_Tutorial_1.ipynb
  - runipy intro/Intro_Tutorial_2.ipynb
  - runipy intro/Intro_Tutorial_3.ipynb
  - runipy intro/Intro_Tutorial_4.ipynb
  - runipy intro/Intro_Tutorial_5.ipynb

  # Runs them some more. Tests running against an existing database.
  - runipy intro/Intro_Tutorial_1.ipynb
  - runipy intro/Intro_Tutorial_2.ipynb
  - runipy intro/Intro_Tutorial_3.ipynb
  - runipy intro/Intro_Tutorial_4.ipynb
  # We do notebook 4 twice to test rerunning in the middle of the workflow
  - runipy intro/Intro_Tutorial_4.ipynb
  - runipy intro/Intro_Tutorial_5.ipynb

  # Run Categorical notebook
  - rm intro/snorkel.db
  - runipy intro/Intro_Tutorial_Categorical.ipynb

  # Run CDR tutorials
  - runipy cdr/CDR_Tutorial_1.ipynb
  - runipy cdr/CDR_Tutorial_2.ipynb
  - runipy cdr/CDR_Tutorial_3.ipynb

  # TODO check outputs, upload results, etc.
  # for more ideas, see: https://github.com/rossant/ipycache/issues/7

after_success:
  - killall java

after_failure:
  - killall java
