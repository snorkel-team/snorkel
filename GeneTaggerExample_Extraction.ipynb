{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging genes with ddlite: candidate extraction\n",
    "\n",
    "## Introduction\n",
    "In this example **ddlite** app, we'll build a gene tagger from scratch. Here's why we developed ddlite:\n",
    "\n",
    "* To provide a lighter-weight interface to structured information extraction for new DeepDive users\n",
    "* To help advanced DeepDive rapidly develop and prototype applications and distant supervision rules\n",
    "* To investigate DeepDive's data programming approach to building inference systems\n",
    "\n",
    "This example is centered around the second item. Domain-specific tagging systems take months or years to develop. They use hand-crafted model circuitry and accurate, hand-labeled training data. We're going to try to build a pretty good one in a few minutes with none of those things. The generalized extraction and learning utilities provided by ddlite will allow us to turn a sampling of article abstracts and some basic domain knowledge into an automated tagging system. Specifically, we want an accurate tagger for genes in academic articles. We have comprehensive dictionaries of genes, but applying a simple matching rule might yield a lot of false positives. For example, \"p53\" might get tagged as a gene if it refers to a page number. Our goal is to use distant supervision to improve precision.\n",
    "\n",
    "Here's the pipeline we'll follow:\n",
    "\n",
    "1. Obtain and parse input data (relevant article abstracts from PubMed)\n",
    "2. Extract candidates for tagging\n",
    "3. Generate features\n",
    "4. Write distant supervision rules\n",
    "5. Learn the tagging model\n",
    "6. Iterate on distant supervision rules\n",
    "\n",
    "Parts 1 and 2 are covered in this notebook, and parts 3 through 6 are covered in `GeneTaggerExample_Learning.ipynb`. Let's get to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cPickle\n",
    "from ddlite import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the input data\n",
    "We already downloaded the raw HTML for 150 gene-related article pages from PubMed using the `pubmed_gene_html.py` script. These can be found in the `data` folder. We can use ddlite's `DocParser` to read in the article text. There's a general HTML parser which finds visible text, but we can do better by writing a more specific version to just grab the abstract text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutations in BCS1L, a respiratory chain complex III assembly chaperone, constitute a major cause of mitochondrial complex III deficiency and are associated with GRACILE and Bjrnstad syndromes. Here we describe a 4-year-old infant with hyperlactacidemia, mild liver dysfunction, hypotonia, growth and psychomotor retardation, dysmorphic features and mitochondrial complex III deficiency. Respiratory chain enzyme activities showed an isolated complex III defect in muscle and fibroblasts. Sequencing and polymerase chain reaction-restriction fragment length polymorphism (PCR-RFLP) analysis revealed a novel homozygous BCS1L mutation, c.148A>G, which caused a p.T50A substitution at an evolutionarily conserved BCS1L region. The severity of the complex III enzyme defect correlated with decreased amounts of BCS1L and respiratory chain complex III in the affected tissues. Our findings support a pathogenic role for the novel BCS1L mutation in a patient with a singular clinical phenotype.\n"
     ]
    }
   ],
   "source": [
    "class PubMedAbstractParser(HTMLParser):\n",
    "    def _cleaner(self, s):\n",
    "        return (s.parent.name == 'abstracttext')\n",
    "\n",
    "dp = DocParser('gene_tag_example/data/', PubMedAbstractParser())\n",
    "docs = list(dp.parseDocs())\n",
    "print docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use CoreNLP via ddlite's `SentenceParser` to parse each sentence. `DocParser` can handle this too; we didn't really need that call above. This can take a little while, so if the example has already been run, we'll reload it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.6 s, sys: 248 ms, total: 12.8 s\n",
      "Wall time: 24.2 s\n",
      "Sentence(words=['Mutations', 'in', 'BCS1L', ',', 'a', 'respiratory', 'chain', 'complex', 'III', 'assembly', 'chaperone', ',', 'constitute', 'a', 'major', 'cause', 'of', 'mitochondrial', 'complex', 'III', 'deficiency', 'and', 'are', 'associated', 'with', 'GRACILE', 'and', 'Bjrnstad', 'syndromes', '.'], lemmas=['mutation', 'in', 'bcs1l', ',', 'a', 'respiratory', 'chain', 'complex', 'iii', 'assembly', 'chaperone', ',', 'constitute', 'a', 'major', 'cause', 'of', 'mitochondrial', 'complex', 'iii', 'deficiency', 'and', 'be', 'associate', 'with', 'gracile', 'and', 'bjrnstad', 'syndrome', '.'], poses=['NNS', 'IN', 'NN', ',', 'DT', 'JJ', 'NN', 'NN', 'CD', 'NN', 'NN', ',', 'VBP', 'DT', 'JJ', 'NN', 'IN', 'JJ', 'NN', 'CD', 'NN', 'CC', 'VBP', 'VBN', 'IN', 'NN', 'CC', 'NN', 'NNS', '.'], dep_parents=[13, 3, 1, 3, 11, 11, 11, 11, 11, 11, 3, 3, 0, 16, 16, 13, 21, 21, 21, 21, 16, 13, 24, 13, 26, 24, 26, 29, 26, 13], dep_labels=['nsubj', 'case', 'nmod', 'punct', 'det', 'amod', 'compound', 'compound', 'nummod', 'compound', 'appos', 'punct', 'ROOT', 'det', 'amod', 'dobj', 'case', 'amod', 'compound', 'nummod', 'nmod', 'cc', 'auxpass', 'conj', 'case', 'nmod', 'cc', 'compound', 'conj', 'punct'], sent_id=0, doc_id=0)\n"
     ]
    }
   ],
   "source": [
    "docs = None\n",
    "\n",
    "pkl_f = 'gene_tag_example/gene_tag_saved_sents_v2.pkl'\n",
    "try:\n",
    "    with open(pkl_f, 'rb') as f:\n",
    "        sents = cPickle.load(f)\n",
    "except:\n",
    "    %time sents = dp.parseDocSentences()\n",
    "    with open(pkl_f, 'w+') as f:\n",
    "        cPickle.dump(sents, f)\n",
    "\n",
    "print sents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting candidates with matchers\n",
    "Extracting candidates for mentions (or relations) in ddlite is done with `Matcher` objects. First, we'll use a `DictionaryMatcher`. We have access to a pretty comprehensive gene dictionary. Let's load it in and create the `DictionaryMatcher`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Schema is: ENSEMBL_ID | NAME | TYPE (refseq, canonical, non-canonical)\n",
    "genes = [line.rstrip().split('\\t')[1] for line in open('gene_tag_example/dicts/ensembl_genes.tsv')]\n",
    "genes = filter(lambda g : len(g) > 2, genes)\n",
    "\n",
    "dm = DictionaryMatch('GeneName', genes, ignore_case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dictionary match should provide fairly high recall, but we may still miss some candidates. We know that gene names are named nouns and are often all uppercase. Let's write our own matcher to catch all-uppercase named nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AllUpperNounsMatcher(Matcher):\n",
    "    def __init__(self, label):\n",
    "        self.label = label\n",
    "        # Regex matcher to find named nouns in part-of-speech tags\n",
    "        self._re_comp = re.compile(\"[A-Z]?NN[A-Z]?\", flags=re.I)\n",
    "    def apply(self, s):\n",
    "        # Get parts-of-speech and words\n",
    "        words = s.__dict__['words']\n",
    "        pos = s.__dict__['poses']\n",
    "        # Get all-cap words\n",
    "        caps = set(idx for idx, w in enumerate(words) if w.upper() == w)\n",
    "        # Convert character index to token index\n",
    "        start_c_idx = [0]\n",
    "        for s in pos:\n",
    "            start_c_idx.append(start_c_idx[-1]+len(s)+1)\n",
    "        # Find regex matches over phrase\n",
    "        phrase = ' '.join(pos)\n",
    "        for match in self._re_comp.finditer(phrase):\n",
    "            # Get start and end indexes for tokens\n",
    "            start = bisect.bisect(start_c_idx, match.start())\n",
    "            end = bisect.bisect(start_c_idx, match.end())\n",
    "            rg = set(range(start-1, end))\n",
    "            # Check if all words in list are capital\n",
    "            if rg.issubset(caps):\n",
    "                yield list(range(start-1, end)), self.label\n",
    "\n",
    "up = AllUpperNounsMatcher('UpNoun')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the candidates\n",
    "To use candidates from both `Matcher` objects, we can use a `MultiMatcher`. We'll use this to extract our candidate entities from the sentences into an `Entities` object. Using both matchers together will provide very high recall, but may have poor precision. In the next demo notebook (`GeneTaggerExample_Learning.ipynb`), we'll write distant supervision rules and learn a model to improve precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M = MultiMatcher(dm, up)\n",
    "E = Entities(sents, M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize contexts for our extractions too. This may help in writing distant supervision rules in `GeneTaggerExample_Learning.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".node {\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".node circle {\n",
       "  fill: #fff;\n",
       "  stroke: steelblue;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "\n",
       ".node text {\n",
       "  font: 12px sans-serif;\n",
       "}\n",
       "\n",
       ".edge {\n",
       "  fill: none;\n",
       "  stroke: #ccc;\n",
       "  stroke-width: 2px;\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".highlight {\n",
       "  stroke: red;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<!--Provide the canvas id (twice) and the words via python string formatting here--!>\n",
       "<div id=\"tree-chart-7117257943788924579\"></div>\n",
       "<div id=\"raw-seq-7117257943788924579\">\n",
       "<span class=\"word-7117257943788924579-0\">Mutations</span> <span class=\"word-7117257943788924579-1\">in</span> <span class=\"word-7117257943788924579-2\">BCS1L</span> <span class=\"word-7117257943788924579-3\">,</span> <span class=\"word-7117257943788924579-4\">a</span> <span class=\"word-7117257943788924579-5\">respiratory</span> <span class=\"word-7117257943788924579-6\">chain</span> <span class=\"word-7117257943788924579-7\">complex</span> <span class=\"word-7117257943788924579-8\">III</span> <span class=\"word-7117257943788924579-9\">assembly</span> <span class=\"word-7117257943788924579-10\">chaperone</span> <span class=\"word-7117257943788924579-11\">,</span> <span class=\"word-7117257943788924579-12\">constitute</span> <span class=\"word-7117257943788924579-13\">a</span> <span class=\"word-7117257943788924579-14\">major</span> <span class=\"word-7117257943788924579-15\">cause</span> <span class=\"word-7117257943788924579-16\">of</span> <span class=\"word-7117257943788924579-17\">mitochondrial</span> <span class=\"word-7117257943788924579-18\">complex</span> <span class=\"word-7117257943788924579-19\">III</span> <span class=\"word-7117257943788924579-20\">deficiency</span> <span class=\"word-7117257943788924579-21\">and</span> <span class=\"word-7117257943788924579-22\">are</span> <span class=\"word-7117257943788924579-23\">associated</span> <span class=\"word-7117257943788924579-24\">with</span> <span class=\"word-7117257943788924579-25\">GRACILE</span> <span class=\"word-7117257943788924579-26\">and</span> <span class=\"word-7117257943788924579-27\">Bjrnstad</span> <span class=\"word-7117257943788924579-28\">syndromes</span> <span class=\"word-7117257943788924579-29\">.</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "$.getScript(\"http://d3js.org/d3.v3.min.js\", function () {\n",
       "// See http://bl.ocks.org/d3noob/8375092\n",
       "// Three vars need to be provided via python string formatting:\n",
       "var chartId = \"7117257943788924579\";\n",
       "var root = {\"attrib\": {\"word\": \"constitute\", \"dep_label\": \"ROOT\", \"pos\": \"VBP\", \"lemma\": \"constitute\", \"word_idx\": \"12\", \"dep_parent\": \"0\"}, \"children\": [{\"attrib\": {\"word\": \"Mutations\", \"dep_label\": \"nsubj\", \"pos\": \"NNS\", \"lemma\": \"mutation\", \"word_idx\": \"0\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"word\": \"BCS1L\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"bcs1l\", \"word_idx\": \"2\", \"dep_parent\": \"1\"}, \"children\": [{\"attrib\": {\"word\": \"in\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"in\", \"word_idx\": \"1\", \"dep_parent\": \"3\"}, \"children\": []}, {\"attrib\": {\"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"3\", \"dep_parent\": \"3\"}, \"children\": []}, {\"attrib\": {\"word\": \"chaperone\", \"dep_label\": \"appos\", \"pos\": \"NN\", \"lemma\": \"chaperone\", \"word_idx\": \"10\", \"dep_parent\": \"3\"}, \"children\": [{\"attrib\": {\"word\": \"a\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"a\", \"word_idx\": \"4\", \"dep_parent\": \"11\"}, \"children\": []}, {\"attrib\": {\"word\": \"respiratory\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"respiratory\", \"word_idx\": \"5\", \"dep_parent\": \"11\"}, \"children\": []}, {\"attrib\": {\"word\": \"chain\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"chain\", \"word_idx\": \"6\", \"dep_parent\": \"11\"}, \"children\": []}, {\"attrib\": {\"word\": \"complex\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"complex\", \"word_idx\": \"7\", \"dep_parent\": \"11\"}, \"children\": []}, {\"attrib\": {\"word\": \"III\", \"dep_label\": \"nummod\", \"pos\": \"CD\", \"lemma\": \"iii\", \"word_idx\": \"8\", \"dep_parent\": \"11\"}, \"children\": []}, {\"attrib\": {\"word\": \"assembly\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"assembly\", \"word_idx\": \"9\", \"dep_parent\": \"11\"}, \"children\": []}]}, {\"attrib\": {\"word\": \",\", \"dep_label\": \"punct\", \"pos\": \",\", \"lemma\": \",\", \"word_idx\": \"11\", \"dep_parent\": \"3\"}, \"children\": []}]}]}, {\"attrib\": {\"word\": \"cause\", \"dep_label\": \"dobj\", \"pos\": \"NN\", \"lemma\": \"cause\", \"word_idx\": \"15\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"word\": \"a\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"a\", \"word_idx\": \"13\", \"dep_parent\": \"16\"}, \"children\": []}, {\"attrib\": {\"word\": \"major\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"major\", \"word_idx\": \"14\", \"dep_parent\": \"16\"}, \"children\": []}, {\"attrib\": {\"word\": \"deficiency\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"deficiency\", \"word_idx\": \"20\", \"dep_parent\": \"16\"}, \"children\": [{\"attrib\": {\"word\": \"of\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"of\", \"word_idx\": \"16\", \"dep_parent\": \"21\"}, \"children\": []}, {\"attrib\": {\"word\": \"mitochondrial\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"mitochondrial\", \"word_idx\": \"17\", \"dep_parent\": \"21\"}, \"children\": []}, {\"attrib\": {\"word\": \"complex\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"complex\", \"word_idx\": \"18\", \"dep_parent\": \"21\"}, \"children\": []}, {\"attrib\": {\"word\": \"III\", \"dep_label\": \"nummod\", \"pos\": \"CD\", \"lemma\": \"iii\", \"word_idx\": \"19\", \"dep_parent\": \"21\"}, \"children\": []}]}]}, {\"attrib\": {\"word\": \"and\", \"dep_label\": \"cc\", \"pos\": \"CC\", \"lemma\": \"and\", \"word_idx\": \"21\", \"dep_parent\": \"13\"}, \"children\": []}, {\"attrib\": {\"word\": \"associated\", \"dep_label\": \"conj\", \"pos\": \"VBN\", \"lemma\": \"associate\", \"word_idx\": \"23\", \"dep_parent\": \"13\"}, \"children\": [{\"attrib\": {\"word\": \"are\", \"dep_label\": \"auxpass\", \"pos\": \"VBP\", \"lemma\": \"be\", \"word_idx\": \"22\", \"dep_parent\": \"24\"}, \"children\": []}, {\"attrib\": {\"word\": \"GRACILE\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"gracile\", \"word_idx\": \"25\", \"dep_parent\": \"24\"}, \"children\": [{\"attrib\": {\"word\": \"with\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"with\", \"word_idx\": \"24\", \"dep_parent\": \"26\"}, \"children\": []}, {\"attrib\": {\"word\": \"and\", \"dep_label\": \"cc\", \"pos\": \"CC\", \"lemma\": \"and\", \"word_idx\": \"26\", \"dep_parent\": \"26\"}, \"children\": []}, {\"attrib\": {\"word\": \"syndromes\", \"dep_label\": \"conj\", \"pos\": \"NNS\", \"lemma\": \"syndrome\", \"word_idx\": \"28\", \"dep_parent\": \"26\"}, \"children\": [{\"attrib\": {\"word\": \"Bjrnstad\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"bjrnstad\", \"word_idx\": \"27\", \"dep_parent\": \"29\"}, \"children\": []}]}]}]}, {\"attrib\": {\"word\": \".\", \"dep_label\": \"punct\", \"pos\": \".\", \"lemma\": \".\", \"word_idx\": \"29\", \"dep_parent\": \"13\"}, \"children\": []}]};\n",
       "var highlightIdxs = [[2]];\n",
       "\n",
       "// Highlight words / nodes\n",
       "var COLORS = [\"#ff5c33\", \"#ffcc00\", \"#33cc33\", \"#3399ff\"];\n",
       "function highlightWords() {\n",
       "  for (var i=0; i < highlightIdxs.length; i++) {\n",
       "    var c = COLORS[i];\n",
       "    var idxs = highlightIdxs[i];\n",
       "    for (var j=0; j < idxs.length; j++) {\n",
       "      d3.selectAll(\".word-\"+chartId+\"-\"+idxs[j]).style(\"stroke\", c).style(\"background\", c);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "// Constants\n",
       "var margin = {top: 20, right: 20, bottom: 20, left: 20},\n",
       "width = 800 - margin.left - margin.right,\n",
       "height = 350 - margin.top - margin.bottom,\n",
       "R = 5;\n",
       "\n",
       "// Create the d3 tree object\n",
       "var tree = d3.layout.tree()\n",
       "  .size([width, height]);\n",
       "\n",
       "// Create the svg canvas\n",
       "var svg = d3.select(\"#tree-chart-\" + chartId)\n",
       "  .append(\"svg\")\n",
       "  .attr(\"width\", width + margin.left + margin.right)\n",
       "  .attr(\"height\", height + margin.top + margin.bottom)\n",
       "  .append(\"g\")\n",
       "  .attr(\"transform\", \"translate(\" + margin.left + \",\" + margin.top + \")\");\n",
       "\n",
       "function renderTree() {\n",
       "  var nodes = tree.nodes(root),\n",
       "  edges = tree.links(nodes);\n",
       "\n",
       "  // Place the nodes\n",
       "  var nodeGroups = svg.selectAll(\"g.node\")\n",
       "    .data(nodes)\n",
       "    .enter().append(\"g\")\n",
       "    .attr(\"class\", \"node\")\n",
       "    .attr(\"transform\", function(d) { return \"translate(\" + d.x + \",\" + d.y + \")\"; });\n",
       "       \n",
       "  // Append circles\n",
       "  nodeGroups.append(\"circle\")\n",
       "    //.on(\"click\", function() {\n",
       "    //  d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"r\", R)\n",
       "    .attr(\"class\", function(d) { return \"word-\"+chartId+\"-\"+d.attrib.word_idx; });\n",
       "     \n",
       "  // Append the actual word\n",
       "  nodeGroups.append(\"text\")\n",
       "    .text(function(d) { return d.attrib.word; })\n",
       "    .attr(\"text-anchor\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? \"start\" : \"middle\"; })\n",
       "    .attr(\"dx\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? R + 3 : 0; })\n",
       "    .attr(\"dy\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? 0 : 3*R + 3; });\n",
       "\n",
       "  // Place the edges\n",
       "  var edgePaths = svg.selectAll(\"path\")\n",
       "    .data(edges)\n",
       "    .enter().append(\"path\")\n",
       "    .attr(\"class\", \"edge\")\n",
       "    .on(\"click\", function() {\n",
       "      d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"d\", d3.svg.diagonal());\n",
       "}\n",
       "\n",
       "renderTree();\n",
       "highlightWords();\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "E[0].render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll pickle the extracted candidates from our `Entities` object for use in `GeneTaggerExample_Learning.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "E.dump_extractions('gene_tag_example/gene_tag_saved_entities.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
