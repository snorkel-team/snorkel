{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding causal genotype-phenotype relations with ddlite: extraction\n",
    "\n",
    "## Introduction\n",
    "In this example **ddlite** app, we'll build a system to indentify causal relationships between genotypes and phenotypes from raw journal articles. For an end-to-end example, see **GeneTaggerExample_Extraction.ipynb** and **GeneTaggerExample_Learning.ipynb**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cPickle, os, sys\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "data_dir = 'gene_phen_relation_example/{}'.format(os.environ.get('docs', 'data'))\n",
    "\n",
    "from ddlite import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the input data\n",
    "We already downloaded the raw HTML for 2800 relevant article pages from PubMed. These can be found in the `data` folder. We can use ddlite's `DocParser` to read in the article text. It uses CoreNLP via ddlite's `SentenceParser` to parse each sentence. This can take a little while, so if the example has already been run, we'll reload it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data from directory gene_phen_relation_example/data\n",
      "CPU times: user 34.6 s, sys: 1.12 s, total: 35.7 s\n",
      "Wall time: 6min 44s\n",
      "Sentence(words=[u'KORA-gen', u'-', u'Resource', u'for', u'population', u'genetics', u',', u'controls', u'and', u'a', u'broad', u'spectrum', u'of', u'disease', u'phenotypes', u'.'], lemmas=[u'kora-gen', u'-', u'Resource', u'for', u'population', u'genetics', u',', u'control', u'and', u'a', u'broad', u'spectrum', u'of', u'disease', u'phenotype', u'.'], poses=[u'NN', u':', u'NNP', u'IN', u'NN', u'NNS', u',', u'NNS', u'CC', u'DT', u'JJ', u'NN', u'IN', u'NN', u'NNS', u'.'], dep_parents=[3, 3, 0, 6, 6, 3, 3, 3, 8, 12, 12, 8, 15, 15, 12, 3], dep_labels=[u'compound', u'punct', u'ROOT', u'case', u'compound', u'nmod', u'punct', u'dep', u'cc', u'det', u'amod', u'conj', u'case', u'compound', u'nmod', u'punct'], sent_id=0, doc_id=0, text=u'KORA-gen - Resource for population genetics, controls and a broad spectrum of disease phenotypes.', token_idxs=[0, 9, 11, 20, 24, 35, 43, 45, 54, 58, 60, 66, 75, 78, 86, 96], doc_name='20700443.txt')\n"
     ]
    }
   ],
   "source": [
    "pkl_f = 'gene_phen_relation_example/gene_phen_saved_sents_v3.pkl'\n",
    "try:\n",
    "    with open(pkl_f, 'rb') as f:\n",
    "        sents = cPickle.load(f)\n",
    "except:\n",
    "    print \"Getting data from directory {}\".format(data_dir)\n",
    "    dp = DocParser(data_dir, TextReader())\n",
    "    %time sents = dp.parseDocSentences()\n",
    "    with open(pkl_f, 'w+') as f:\n",
    "        cPickle.dump(sents, f)\n",
    "\n",
    "print sents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting relation candidates with matchers\n",
    "Extracting candidates for relations in ddlite is done with `Matcher` objects. Here, we'll use two `DictionaryMatcher`s. We have access to pretty comprehensive gene and phenotype dictionaries. Let's load them in and create the `DictionaryMatcher`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Schema is: ENSEMBL_ID | NAME | TYPE (refseq, canonical, non-canonical)\n",
    "genes = [line.rstrip().split('\\t')[1] for line in open('gene_phen_relation_example/dicts/ensembl_genes.tsv')]\n",
    "genes = filter(lambda g : len(g) > 3, genes)\n",
    "\n",
    "# Schema is: HPO_ID | NAME | TYPE (exact, lemma)\n",
    "phenos = [line.rstrip().split('\\t')[1] for line in open('gene_phen_relation_example/dicts/pheno_terms.tsv')]\n",
    "\n",
    "GM = DictionaryMatch(label='G', dictionary=genes, ignore_case=False)\n",
    "PM = DictionaryMatch(label='P', dictionary=phenos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to define more `Matcher` for, say, genes, we could use multiple `Matcher` objects with a `MultiMatcher`. For now, we'll just use the single `DictionaryMatcher` for both classes. We'll use this to extract our candidate relations from the sentences into an `Relations` object. Using just the matchers will likely provide high recall but poor precision. This is because not all genotype-phenotype mention pairs in the same sentence represent a causal pairing. The `Relations` object we create can be used in a `CandidateModel`. This allows us to learn a model to predict whether each candidate pair represents a causal pair or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "R = Relations(sents, GM, PM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize contexts for our extractions too. This may help in writing labeling functions in a learning task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".node {\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".node circle {\n",
       "  fill: #fff;\n",
       "  stroke: steelblue;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "\n",
       ".node text {\n",
       "  font: 12px sans-serif;\n",
       "}\n",
       "\n",
       ".edge {\n",
       "  fill: none;\n",
       "  stroke: #ccc;\n",
       "  stroke-width: 2px;\n",
       "  cursor: pointer;\n",
       "}\n",
       "\n",
       ".highlight {\n",
       "  stroke: red;\n",
       "  stroke-width: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<!--Provide the canvas id (twice) and the words via python string formatting here--!>\n",
       "<div id=\"tree-chart-8632818120679054752\"></div>\n",
       "<div id=\"raw-seq-8632818120679054752\">\n",
       "<span class=\"word-8632818120679054752-0\">Lack</span> <span class=\"word-8632818120679054752-1\">of</span> <span class=\"word-8632818120679054752-2\">_</span> <span class=\"word-8632818120679054752-3\">KIF21A</span> <span class=\"word-8632818120679054752-4\">_</span> <span class=\"word-8632818120679054752-5\">mutations</span> <span class=\"word-8632818120679054752-6\">in</span> <span class=\"word-8632818120679054752-7\">congenital</span> <span class=\"word-8632818120679054752-8\">fibrosis</span> <span class=\"word-8632818120679054752-9\">of</span> <span class=\"word-8632818120679054752-10\">the</span> <span class=\"word-8632818120679054752-11\">extraocular</span> <span class=\"word-8632818120679054752-12\">muscles</span> <span class=\"word-8632818120679054752-13\">type</span> <span class=\"word-8632818120679054752-14\">I</span> <span class=\"word-8632818120679054752-15\">patients</span> <span class=\"word-8632818120679054752-16\">from</span> <span class=\"word-8632818120679054752-17\">consanguineous</span> <span class=\"word-8632818120679054752-18\">Saudi</span> <span class=\"word-8632818120679054752-19\">Arabian</span> <span class=\"word-8632818120679054752-20\">families</span> <span class=\"word-8632818120679054752-21\">.</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "$.getScript(\"http://d3js.org/d3.v3.min.js\", function () {\n",
       "// See http://bl.ocks.org/d3noob/8375092\n",
       "// Three vars need to be provided via python string formatting:\n",
       "var chartId = \"8632818120679054752\";\n",
       "var root = {\"attrib\": {\"token_idx\": \"0\", \"word\": \"Lack\", \"dep_label\": \"ROOT\", \"pos\": \"NN\", \"lemma\": \"lack\", \"word_idx\": \"0\", \"dep_parent\": \"0\"}, \"children\": [{\"attrib\": {\"token_idx\": \"17\", \"word\": \"mutations\", \"dep_label\": \"nmod\", \"pos\": \"NNS\", \"lemma\": \"mutation\", \"word_idx\": \"5\", \"dep_parent\": \"1\"}, \"children\": [{\"attrib\": {\"token_idx\": \"5\", \"word\": \"of\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"of\", \"word_idx\": \"1\", \"dep_parent\": \"6\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"8\", \"word\": \"_\", \"dep_label\": \"nummod\", \"pos\": \"CD\", \"lemma\": \"_\", \"word_idx\": \"2\", \"dep_parent\": \"6\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"9\", \"word\": \"KIF21A\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"kif21a\", \"word_idx\": \"3\", \"dep_parent\": \"6\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"15\", \"word\": \"_\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"_\", \"word_idx\": \"4\", \"dep_parent\": \"6\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"41\", \"word\": \"fibrosis\", \"dep_label\": \"nmod\", \"pos\": \"NN\", \"lemma\": \"fibrosis\", \"word_idx\": \"8\", \"dep_parent\": \"6\"}, \"children\": [{\"attrib\": {\"token_idx\": \"27\", \"word\": \"in\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"in\", \"word_idx\": \"6\", \"dep_parent\": \"9\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"30\", \"word\": \"congenital\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"congenital\", \"word_idx\": \"7\", \"dep_parent\": \"9\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"84\", \"word\": \"patients\", \"dep_label\": \"nmod\", \"pos\": \"NNS\", \"lemma\": \"patient\", \"word_idx\": \"15\", \"dep_parent\": \"9\"}, \"children\": [{\"attrib\": {\"token_idx\": \"50\", \"word\": \"of\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"of\", \"word_idx\": \"9\", \"dep_parent\": \"16\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"53\", \"word\": \"the\", \"dep_label\": \"det\", \"pos\": \"DT\", \"lemma\": \"the\", \"word_idx\": \"10\", \"dep_parent\": \"16\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"57\", \"word\": \"extraocular\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"extraocular\", \"word_idx\": \"11\", \"dep_parent\": \"16\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"69\", \"word\": \"muscles\", \"dep_label\": \"compound\", \"pos\": \"NNS\", \"lemma\": \"muscle\", \"word_idx\": \"12\", \"dep_parent\": \"16\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"77\", \"word\": \"type\", \"dep_label\": \"compound\", \"pos\": \"NN\", \"lemma\": \"type\", \"word_idx\": \"13\", \"dep_parent\": \"16\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"82\", \"word\": \"I\", \"dep_label\": \"nummod\", \"pos\": \"CD\", \"lemma\": \"i\", \"word_idx\": \"14\", \"dep_parent\": \"16\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"127\", \"word\": \"families\", \"dep_label\": \"nmod\", \"pos\": \"NNS\", \"lemma\": \"family\", \"word_idx\": \"20\", \"dep_parent\": \"16\"}, \"children\": [{\"attrib\": {\"token_idx\": \"93\", \"word\": \"from\", \"dep_label\": \"case\", \"pos\": \"IN\", \"lemma\": \"from\", \"word_idx\": \"16\", \"dep_parent\": \"21\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"98\", \"word\": \"consanguineous\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"consanguineous\", \"word_idx\": \"17\", \"dep_parent\": \"21\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"113\", \"word\": \"Saudi\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"saudi\", \"word_idx\": \"18\", \"dep_parent\": \"21\"}, \"children\": []}, {\"attrib\": {\"token_idx\": \"119\", \"word\": \"Arabian\", \"dep_label\": \"amod\", \"pos\": \"JJ\", \"lemma\": \"arabian\", \"word_idx\": \"19\", \"dep_parent\": \"21\"}, \"children\": []}]}]}]}]}, {\"attrib\": {\"token_idx\": \"135\", \"word\": \".\", \"dep_label\": \"punct\", \"pos\": \".\", \"lemma\": \".\", \"word_idx\": \"21\", \"dep_parent\": \"1\"}, \"children\": []}]};\n",
       "var highlightIdxs = [[3], [7, 8, 9, 10, 11, 12]];\n",
       "\n",
       "// Highlight words / nodes\n",
       "var COLORS = [\"#ff5c33\", \"#ffcc00\", \"#33cc33\", \"#3399ff\"];\n",
       "function highlightWords() {\n",
       "  for (var i=0; i < highlightIdxs.length; i++) {\n",
       "    var c = COLORS[i];\n",
       "    var idxs = highlightIdxs[i];\n",
       "    for (var j=0; j < idxs.length; j++) {\n",
       "      d3.selectAll(\".word-\"+chartId+\"-\"+idxs[j]).style(\"stroke\", c).style(\"background\", c);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "// Constants\n",
       "var margin = {top: 20, right: 20, bottom: 20, left: 20},\n",
       "width = 800 - margin.left - margin.right,\n",
       "height = 350 - margin.top - margin.bottom,\n",
       "R = 5;\n",
       "\n",
       "// Create the d3 tree object\n",
       "var tree = d3.layout.tree()\n",
       "  .size([width, height]);\n",
       "\n",
       "// Create the svg canvas\n",
       "var svg = d3.select(\"#tree-chart-\" + chartId)\n",
       "  .append(\"svg\")\n",
       "  .attr(\"width\", width + margin.left + margin.right)\n",
       "  .attr(\"height\", height + margin.top + margin.bottom)\n",
       "  .append(\"g\")\n",
       "  .attr(\"transform\", \"translate(\" + margin.left + \",\" + margin.top + \")\");\n",
       "\n",
       "function renderTree() {\n",
       "  var nodes = tree.nodes(root),\n",
       "  edges = tree.links(nodes);\n",
       "\n",
       "  // Place the nodes\n",
       "  var nodeGroups = svg.selectAll(\"g.node\")\n",
       "    .data(nodes)\n",
       "    .enter().append(\"g\")\n",
       "    .attr(\"class\", \"node\")\n",
       "    .attr(\"transform\", function(d) { return \"translate(\" + d.x + \",\" + d.y + \")\"; });\n",
       "       \n",
       "  // Append circles\n",
       "  nodeGroups.append(\"circle\")\n",
       "    //.on(\"click\", function() {\n",
       "    //  d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"r\", R)\n",
       "    .attr(\"class\", function(d) { return \"word-\"+chartId+\"-\"+d.attrib.word_idx; });\n",
       "     \n",
       "  // Append the actual word\n",
       "  nodeGroups.append(\"text\")\n",
       "    .text(function(d) { return d.attrib.word; })\n",
       "    .attr(\"text-anchor\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? \"start\" : \"middle\"; })\n",
       "    .attr(\"dx\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? R + 3 : 0; })\n",
       "    .attr(\"dy\", function(d) { \n",
       "      return d.children && d.children.length > 0 ? 0 : 3*R + 3; });\n",
       "\n",
       "  // Place the edges\n",
       "  var edgePaths = svg.selectAll(\"path\")\n",
       "    .data(edges)\n",
       "    .enter().append(\"path\")\n",
       "    .attr(\"class\", \"edge\")\n",
       "    .on(\"click\", function() {\n",
       "      d3.select(this).classed(\"highlight\", !d3.select(this).classed(\"highlight\")); })\n",
       "    .attr(\"d\", d3.svg.diagonal());\n",
       "}\n",
       "\n",
       "renderTree();\n",
       "highlightWords();\n",
       "});\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "R[2].render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can pickle the extracted candidates from our `Relations` object for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "R.dump_candidates('gene_phen_relation_example/gene_phen_saved_relations_v4.pkl')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
