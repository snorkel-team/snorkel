{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HARDWARE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "\"\"\"\n",
    "To change attributes:\n",
    "1) Change ATTRIBUTE and you're good to go\n",
    "\"\"\"\n",
    "ATTRIBUTE = 'stg_temp_min'\n",
    "COUNTER = '_scaling'\n",
    "PARALLEL = 80\n",
    "PARALLEL_EXTRACTION = 8\n",
    "SCALE_SIZE = 1000\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "snorkel_postgres = os.environ['SNORKELDB'].startswith('postgres')\n",
    "print snorkel_postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if snorkel_postgres:\n",
    "    os.environ['SNORKELDBNAME'] = ATTRIBUTE + str(COUNTER)\n",
    "    print os.system(\"dropdb \" + os.environ['SNORKELDBNAME'])\n",
    "    print os.system(\"createdb \" + os.environ['SNORKELDBNAME'])\n",
    "    print \"SNORKELDBNAME = %s\" % os.environ['SNORKELDBNAME']\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if snorkel_postgres:\n",
    "    from snorkel.async_parser import parse_corpus, HTMLParser, AsyncOmniParser\n",
    "    print \"Starting async parse...\"\n",
    "    \n",
    "    # PARSE TRAIN\n",
    "    docs_path = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/symlinked_html/'\n",
    "    pdf_path = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/symlinked_pdf/'\n",
    "    doc_parser = HTMLParser()\n",
    "    context_parser = AsyncOmniParser(blacklist=['style'], flatten=['span','br'], \n",
    "                                     tabular=True, lingual=True,\n",
    "                                     visual=True, pdf_path=pdf_path)\n",
    "    %time corpus = parse_corpus(session, 'Hardware Scale', docs_path,\\\n",
    "                                doc_parser, context_parser,\\\n",
    "                                max_docs=SCALE_SIZE, parallel=PARALLEL)\n",
    "\n",
    "    print \"%s contains %d documents\" % (corpus, len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing Results\n",
    "\n",
    "All parsing features to true:\n",
    "\n",
    "|    ATTRIBUTE | PARALLEL | PARALLEL_EXTRACTION | SCALE_SIZE |     RUNTIME |\n",
    "| -----------: | -------: | ------------------: | ---------: | ----------: |\n",
    "| stg_temp_min |       80 |                   8 |        1e2 |       33.2s |\n",
    "| stg_temp_min |       80 |                   8 |        1e3 |  2min 13sec |\n",
    "| stg_temp_min |       80 |                   8 |        1e4 | 22min 21sec |\n",
    "| stg_temp_min |       80 |                   8 |        1e5 | 3h 41min 1s |\n",
    "| stg_temp_min |       80 |                   8 |        1e6 |             |\n",
    "\n",
    "\n",
    "Turning Lingual to False\n",
    "\n",
    "Run 0: Parallel = 80, SCALE_SIZE = 1e4. Runtime = 11min 34s\n",
    "\n",
    "Turing visual to False\n",
    "\n",
    "Run 0: Parallel = 80, SCALE_SIZE = 1e4. Runtime = 21min 28s\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "session.commit()\n",
    "\n",
    "Part_Attr = candidate_subclass('Part_Attr', ['part','attr'])\n",
    "\n",
    "from hardware_matchers import get_matcher\n",
    "\n",
    "dict_path = os.environ['SNORKELHOME'] +\\\n",
    "    '/tutorials/tables/data/hardware/gold_raw/digikey_part_dictionary.csv'\n",
    "part_matcher = get_matcher('part', dict_path)\n",
    "attr_matcher = get_matcher(ATTRIBUTE)\n",
    "\n",
    "from hardware_spaces import get_space\n",
    "    \n",
    "part_ngrams = get_space('part')\n",
    "attr_ngrams = get_space(ATTRIBUTE)\n",
    "\n",
    "from hardware_throttlers import get_throttler\n",
    "\n",
    "throttler = get_throttler(ATTRIBUTE)\n",
    "# throttler = None\n",
    "\n",
    "from snorkel.models import Corpus\n",
    "from snorkel.candidates import CandidateExtractor\n",
    "from snorkel.utils import get_ORM_instance\n",
    "from snorkel.async_candidates import parallel_extract\n",
    "\n",
    "ce = CandidateExtractor(Part_Attr, \n",
    "                        [part_ngrams, attr_ngrams], \n",
    "                        [part_matcher, attr_matcher], \n",
    "                        throttler=throttler)\n",
    "\n",
    "corpus_names = ['Hardware Scale']\n",
    "\n",
    "for corpus_name in corpus_names:\n",
    "    corpus = get_ORM_instance(Corpus, session, corpus_name)\n",
    "    print \"Extracting Candidates from %s\" % corpus\n",
    "    %time candidates = parallel_extract(session, ce, corpus, \\\n",
    "                                        corpus_name + ' Candidates', \\\n",
    "                                        parallel=PARALLEL_EXTRACTION)\n",
    "    session.add(candidates)\n",
    "    print \"%s contains %d Candidates\" % (candidates, len(candidates))\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing Results\n",
    "\n",
    "|    ATTRIBUTE | PARALLEL | PARALLEL_EXTRACTION | SCALE_SIZE |   RUNTIME |\n",
    "| -----------: | -------: | ------------------: | ---------: | --------: |\n",
    "| stg_temp_min |       80 |                   8 |        1e2 |     49.6s |\n",
    "| stg_temp_min |       80 |                   8 |        1e3 | 37min 25s |\n",
    "| stg_temp_min |       80 |                   8 |        1e4 |           |\n",
    "| stg_temp_min |       80 |                   8 |        1e5 |           |\n",
    "| stg_temp_min |       80 |                   8 |        1e6 |           |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "from snorkel.utils import get_ORM_instance\n",
    "\n",
    "scale = get_ORM_instance(CandidateSet, session, 'Hardware Scale Candidates')\n",
    "\n",
    "from snorkel.async_annotations import annotate\n",
    "print \"Starting async featurization...\"\n",
    "%time F_scale = annotate(scale, parallel=PARALLEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing Results\n",
    "\n",
    "|    ATTRIBUTE | PARALLEL | PARALLEL_EXTRACTION | SCALE_SIZE |   RUNTIME |\n",
    "| -----------: | -------: | ------------------: | ---------: | --------: |\n",
    "| stg_temp_min |       80 |                   8 |        1e2 |  2min 17s |\n",
    "| stg_temp_min |       80 |                   8 |        1e3 | 54min 36s |\n",
    "| stg_temp_min |       80 |                   8 |        1e4 |           |\n",
    "| stg_temp_min |       80 |                   8 |        1e5 |           |\n",
    "| stg_temp_min |       80 |                   8 |        1e6 |           |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hardware_lfs import get_lfs\n",
    "\n",
    "LFs = get_lfs(ATTRIBUTE)\n",
    "\n",
    "from snorkel.async_annotations import annotate\n",
    "%time L_scale = annotate(scale, parallel=PARALLEL, lfs=LFs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing Results\n",
    "\n",
    "|    ATTRIBUTE | PARALLEL | PARALLEL_EXTRACTION | SCALE_SIZE |   RUNTIME |\n",
    "| -----------: | -------: | ------------------: | ---------: | --------: |\n",
    "| stg_temp_min |       80 |                   8 |        1e2 |     48.9s |\n",
    "| stg_temp_min |       80 |                   8 |        1e3 | 35min 38s |\n",
    "| stg_temp_min |       80 |                   8 |        1e4 |           |\n",
    "| stg_temp_min |       80 |                   8 |        1e5 |           |\n",
    "| stg_temp_min |       80 |                   8 |        1e6 |           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import NaiveBayes\n",
    "\n",
    "gen_model = NaiveBayes()\n",
    "%time gen_model.train(L_scale, n_iter=2000, rate=1e-3, mu=1e-6)\n",
    "scale_marginals = gen_model.marginals(L_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import LogReg\n",
    "\n",
    "disc_model = LogReg()\n",
    "%time disc_model.train(F_scale, scale_marginals, n_iter=5000, rate=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing Results\n",
    "\n",
    "|    ATTRIBUTE | PARALLEL | PARALLEL_EXTRACTION | SCALE_SIZE | GEN RUNTIME | DISC RUNTIME |\n",
    "| -----------: | -------: | ------------------: | ---------: | ----------: | -----------: |\n",
    "| stg_temp_min |       80 |                   8 |        1e2 |    2min 20s |        59.8s |\n",
    "| stg_temp_min |       80 |                   8 |        1e3 |   16min 25s |    15min 48s |\n",
    "| stg_temp_min |       80 |                   8 |        1e4 |             |              |\n",
    "| stg_temp_min |       80 |                   8 |        1e5 |             |              |\n",
    "| stg_temp_min |       80 |                   8 |        1e6 |             |              |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from snorkel.models import CandidateSet\n",
    "from hardware_utils import load_hardware_labels\n",
    "\n",
    "data_sets = ['Scale']\n",
    "gold_file = {}\n",
    "gold_file['Scale'] = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/dev/hardware_dev_gold.csv'\n",
    "\n",
    "for data_set in data_sets:\n",
    "    candidate_set_name = 'Hardware %s Candidates' % data_set\n",
    "    candidates = session.query(CandidateSet).filter(\n",
    "        CandidateSet.name == candidate_set_name).one()\n",
    "    label_set_name = 'Hardware %s Candidates -- Gold' % data_set\n",
    "    annotation_key_name = 'Hardware %s Labels -- Gold' % data_set\n",
    "    gold_candidates, annotation_key = load_hardware_labels(session,\\\n",
    "                           label_set_name, \\\n",
    "                           annotation_key_name, \\\n",
    "                           candidates, \\\n",
    "                           gold_file[data_set], \\\n",
    "                           ATTRIBUTE)\n",
    "    candidates_gold = session.query(CandidateSet).filter(\n",
    "        CandidateSet.name == candidate_set_name + ' -- Gold').one()\n",
    "    print \"%d/%d Candidates in %s have positive Labels\" % (\n",
    "        len(candidates_gold), len(candidates), candidates)\n",
    "\n",
    "    \n",
    "dev_gold = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Scale Candidates -- Gold').one()\n",
    "\n",
    "from snorkel.annotations import LabelManager\n",
    "label_manager = LabelManager()\n",
    "L_scale = label_manager.load(session, scale, 'Hardware Scale Labels -- Gold')\n",
    "L_scale.shape\n",
    "\n",
    "%time tp, fp, tn, fn = disc_model.score(F_scale, L_scale, dev_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing Results\n",
    "\n",
    "| ATTRIBUTE    | PARALLEL | PARALLEL_EXTRACTION | SCALE_SIZE |    RUNTIME |\n",
    "| :----------- | -------: | ------------------: | ---------: | ---------: |\n",
    "| stg_temp_min |       80 |                   8 |        1e2 | X |\n",
    "| stg_temp_min |       80 |                   8 |        1e3 |   2min 33s         |\n",
    "| stg_temp_min |       80 |                   8 |        1e4 |            |\n",
    "| stg_temp_min |       80 |                   8 |        1e5 |            |\n",
    "| stg_temp_min |       80 |                   8 |        1e6 |            |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
