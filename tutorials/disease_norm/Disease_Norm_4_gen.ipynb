{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disease Norm\n",
    "\n",
    "In this example, we'll be writing an application to extract *mentions of* diseases from Pubmed abstracts, using annotations from the [BioCreative CDR Challenge](http://www.biocreative.org/resources/corpora/biocreative-v-cdr-corpus/).  This tutorial, which has 5 parts, walks through the process of constructing a model to classify _candidate_ disease mentions as either true (i.e., that it is truly a mention of a disease) or false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan of action:\n",
    "\n",
    "Two types of LFs:\n",
    "1. TYPE I: Leveraging sources of WS (e.g. DS)\n",
    "2. TYPE II: Expressing heuristics (e.g. magnifying user effort)\n",
    "\n",
    "TYPE I:\n",
    "- Need to break up MESH into subtrees and have each one be an LF!\n",
    "- Need to provide negative signal\n",
    "\n",
    "TYPE II:\n",
    "- Conduct \"simulated expert\" experiment: go through, label examples, write LFs- what is the effective multiplier over binary labeling??\n",
    "    * E.g. \"renal failure\"; add {\"renal\" -> \"kidney\"} to synonym map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Disease = candidate_subclass('Disease', ['disease'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading `CandidateSet` objects\n",
    "\n",
    "We reload the training and development `CandidateSet` objects from the previous parts of the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "\n",
    "train = session.query(CandidateSet).filter(CandidateSet.name == 'CDR Training Candidates').one()\n",
    "dev = session.query(CandidateSet).filter(CandidateSet.name == 'CDR Development Candidates').one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing some multinomial LFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TYPE I LF: Subsets of MESH dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cPickle import load\n",
    "\n",
    "MESH_to_CID = load(open('MESH_to_CID.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 28472 entries\n"
     ]
    }
   ],
   "source": [
    "from utils import load_mesh_raw\n",
    "\n",
    "mesh_entries = load_mesh_raw('data/desc2017.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the LFGs as key-value generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mesh_tree = defaultdict(list)\n",
    "for entry in mesh_entries:\n",
    "    mid, tree_nums, terms = entry\n",
    "    for tn in tree_nums:\n",
    "        path = [tn[0]] + tn[1:].split(\".\")\n",
    "        for term in terms:\n",
    "            mesh_tree[term].append((mid, path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('D007952', ['C', '04', '557', '337', '595']),\n",
       " ('D007952', ['C', '04', '557', '595', '500', '500']),\n",
       " ('D007952', ['C', '20', '683', '515', '845', '500'])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh_tree.values()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LFG_MESH_exact(c):\n",
    "    p = c.disease.get_span().lower()\n",
    "    if p in mesh_tree:\n",
    "        seen = set()\n",
    "        for mid, path in mesh_tree[p]:\n",
    "            key   = \"_\".join(path[:2])\n",
    "            if key not in seen:\n",
    "                seen.add(key)\n",
    "                value = MESH_to_CID[mid] if path[0] in ['C', 'F'] else -1\n",
    "                yield key, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelManager\n",
    "\n",
    "label_manager = LabelManager()\n",
    "L_gold_dev = label_manager.load(session, dev, \"CDR Development Label Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<29853x1 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 29853 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_gold_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n",
      "CPU times: user 1min 37s, sys: 17.9 s, total: 1min 55s\n",
      "Wall time: 1min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<29853x103 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 10832 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_dev = label_manager.create(session, dev, 'LF Labels', f=LFG_MESH_exact)\n",
    "L_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>coverage</th>\n",
       "      <th>overlaps</th>\n",
       "      <th>conflicts</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>G_07</th>\n",
       "      <td>0</td>\n",
       "      <td>0.003517</td>\n",
       "      <td>0.003015</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G_08</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.985075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_23</th>\n",
       "      <td>2</td>\n",
       "      <td>0.018524</td>\n",
       "      <td>0.013734</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.833635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_08</th>\n",
       "      <td>3</td>\n",
       "      <td>0.001306</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.871795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_03</th>\n",
       "      <td>4</td>\n",
       "      <td>0.028004</td>\n",
       "      <td>0.012394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F_01</th>\n",
       "      <td>5</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.169014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_01</th>\n",
       "      <td>6</td>\n",
       "      <td>0.013868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.995169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_10</th>\n",
       "      <td>7</td>\n",
       "      <td>0.016347</td>\n",
       "      <td>0.012394</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>0.838115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E_03</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_02</th>\n",
       "      <td>9</td>\n",
       "      <td>0.038690</td>\n",
       "      <td>0.015945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_04</th>\n",
       "      <td>10</td>\n",
       "      <td>0.009513</td>\n",
       "      <td>0.007872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F_02</th>\n",
       "      <td>11</td>\n",
       "      <td>0.005527</td>\n",
       "      <td>0.003718</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_14</th>\n",
       "      <td>12</td>\n",
       "      <td>0.008441</td>\n",
       "      <td>0.003216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.960317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G_04</th>\n",
       "      <td>13</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.885714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_17</th>\n",
       "      <td>14</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.986111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E_02</th>\n",
       "      <td>15</td>\n",
       "      <td>0.010686</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.996865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E_05</th>\n",
       "      <td>16</td>\n",
       "      <td>0.015375</td>\n",
       "      <td>0.010351</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.997821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_05</th>\n",
       "      <td>17</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_06</th>\n",
       "      <td>18</td>\n",
       "      <td>0.008341</td>\n",
       "      <td>0.007537</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.995984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_12</th>\n",
       "      <td>19</td>\n",
       "      <td>0.003350</td>\n",
       "      <td>0.003350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_13</th>\n",
       "      <td>20</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003651</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.991150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_11</th>\n",
       "      <td>21</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_12</th>\n",
       "      <td>22</td>\n",
       "      <td>0.009145</td>\n",
       "      <td>0.005929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.992674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_05</th>\n",
       "      <td>23</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M_01</th>\n",
       "      <td>24</td>\n",
       "      <td>0.032392</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G_01</th>\n",
       "      <td>25</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.001742</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_01</th>\n",
       "      <td>27</td>\n",
       "      <td>0.001608</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_04</th>\n",
       "      <td>28</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.987179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_25</th>\n",
       "      <td>29</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.824561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_02</th>\n",
       "      <td>73</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G_10</th>\n",
       "      <td>74</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_03</th>\n",
       "      <td>75</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J_02</th>\n",
       "      <td>76</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_01</th>\n",
       "      <td>77</td>\n",
       "      <td>0.001641</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_07</th>\n",
       "      <td>78</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_04</th>\n",
       "      <td>79</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_14</th>\n",
       "      <td>80</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_02</th>\n",
       "      <td>81</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_26</th>\n",
       "      <td>82</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.821429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_16</th>\n",
       "      <td>83</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G_05</th>\n",
       "      <td>84</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E_07</th>\n",
       "      <td>85</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G_02</th>\n",
       "      <td>86</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I_02</th>\n",
       "      <td>87</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J_03</th>\n",
       "      <td>88</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_25</th>\n",
       "      <td>89</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J_01</th>\n",
       "      <td>90</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_09</th>\n",
       "      <td>91</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G_03</th>\n",
       "      <td>92</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C_09</th>\n",
       "      <td>93</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G_12</th>\n",
       "      <td>94</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_10</th>\n",
       "      <td>95</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G_14</th>\n",
       "      <td>96</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_06</th>\n",
       "      <td>97</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_03</th>\n",
       "      <td>98</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D_20</th>\n",
       "      <td>99</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B_05</th>\n",
       "      <td>100</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V_01</th>\n",
       "      <td>101</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_13</th>\n",
       "      <td>102</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        j  coverage  overlaps  conflicts  accuracy\n",
       "G_07    0  0.003517  0.003015   0.000435  0.933333\n",
       "G_08    1  0.002244  0.000770   0.000033  0.985075\n",
       "C_23    2  0.018524  0.013734   0.002412  0.833635\n",
       "C_08    3  0.001306  0.000770   0.000000  0.871795\n",
       "D_03    4  0.028004  0.012394   0.000000  1.000000\n",
       "F_01    5  0.004757  0.001943   0.000134  0.169014\n",
       "B_01    6  0.013868  0.000000   0.000000  0.995169\n",
       "C_10    7  0.016347  0.012394   0.001072  0.838115\n",
       "E_03    8  0.000804  0.000033   0.000000  0.791667\n",
       "D_02    9  0.038690  0.015945   0.000000  1.000000\n",
       "D_04   10  0.009513  0.007872   0.000000  1.000000\n",
       "F_02   11  0.005527  0.003718   0.002211  0.200000\n",
       "C_14   12  0.008441  0.003216   0.000000  0.960317\n",
       "G_04   13  0.001172  0.000670   0.000234  0.885714\n",
       "C_17   14  0.002412  0.001876   0.000000  0.986111\n",
       "E_02   15  0.010686  0.000904   0.000033  0.996865\n",
       "E_05   16  0.015375  0.010351   0.000469  0.997821\n",
       "N_05   17  0.004455  0.004455   0.000067  1.000000\n",
       "N_06   18  0.008341  0.007537   0.000100  0.995984\n",
       "C_12   19  0.003350  0.003350   0.000000  1.000000\n",
       "C_13   20  0.003785  0.003651   0.000033  0.991150\n",
       "A_11   21  0.002680  0.001407   0.000000  1.000000\n",
       "D_12   22  0.009145  0.005929   0.000000  0.992674\n",
       "D_05   23  0.000368  0.000368   0.000000  1.000000\n",
       "M_01   24  0.032392  0.000469   0.000033  1.000000\n",
       "G_01   25  0.002211  0.000804   0.000636  0.712121\n",
       "D_26   26  0.001742  0.000167   0.000000  1.000000\n",
       "A_01   27  0.001608  0.000603   0.000000  1.000000\n",
       "N_04   28  0.002613  0.000603   0.000000  0.987179\n",
       "C_25   29  0.001909  0.001574   0.000603  0.824561\n",
       "...   ...       ...       ...        ...       ...\n",
       "A_02   73  0.000703  0.000368   0.000000  1.000000\n",
       "G_10   74  0.000368  0.000368   0.000033  0.818182\n",
       "A_03   75  0.000737  0.000000   0.000000  1.000000\n",
       "J_02   76  0.000502  0.000502   0.000000  1.000000\n",
       "H_01   77  0.001641  0.001440   0.000000  1.000000\n",
       "C_07   78  0.000134  0.000134   0.000000  0.750000\n",
       "A_04   79  0.000033  0.000033   0.000000  1.000000\n",
       "A_14   80  0.000100  0.000067   0.000000  1.000000\n",
       "H_02   81  0.001507  0.000134   0.000000  1.000000\n",
       "C_26   82  0.000938  0.000770   0.000636  0.821429\n",
       "A_16   83  0.000134  0.000000   0.000000  1.000000\n",
       "G_05   84  0.000502  0.000268   0.000033  1.000000\n",
       "E_07   85  0.000234  0.000033   0.000000  1.000000\n",
       "G_02   86  0.001139  0.000670   0.000100  1.000000\n",
       "I_02   87  0.000100  0.000067   0.000000  1.000000\n",
       "J_03   88  0.000134  0.000134   0.000000  1.000000\n",
       "D_25   89  0.000134  0.000134   0.000000  1.000000\n",
       "J_01   90  0.000268  0.000134   0.000000  1.000000\n",
       "A_09   91  0.000837  0.000603   0.000000  1.000000\n",
       "G_03   92  0.000971  0.000871   0.000000  1.000000\n",
       "C_09   93  0.000201  0.000201   0.000000  0.500000\n",
       "G_12   94  0.000234  0.000100   0.000100  0.571429\n",
       "A_10   95  0.000904  0.000703   0.000000  1.000000\n",
       "G_14   96  0.000703  0.000603   0.000502  1.000000\n",
       "A_06   97  0.000201  0.000100   0.000000  1.000000\n",
       "B_03   98  0.000067  0.000000   0.000000  1.000000\n",
       "D_20   99  0.000100  0.000100   0.000000  1.000000\n",
       "B_05  100  0.000033  0.000033   0.000000  1.000000\n",
       "V_01  101  0.000033  0.000033   0.000000  1.000000\n",
       "A_13  102  0.000100  0.000000   0.000000  1.000000\n",
       "\n",
       "[103 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_dev.lf_stats(labels=L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/matplotlib/__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named numbskull",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-57a045acdf1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerativeModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgen_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerativeModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgen_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aratner/repos/snorkel/snorkel/learning/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdisc_learning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNoiseAwareModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogReg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogRegSKLearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgen_learning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNaiveBayes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGenerativeModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGenerativeModelWeights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mDEP_SIMILAR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEP_FIXING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEP_REINFORCING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDEP_EXCLUSIVE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mparam_search\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSearch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRandomSearch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mListParameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRangeParameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/aratner/repos/snorkel/snorkel/learning/gen_learning.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdisc_learning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNoiseAwareModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumbskull\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNumbSkull\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumbskull\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFACTORS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumbskull\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumbskulltypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWeight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFactorToVar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named numbskull"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "\n",
    "gen_model = GenerativeModel()\n",
    "gen_model.train(L_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "\n",
    "0. _DONE: Add negative labels to candidates..._\n",
    "1. _DONE: Get empirical LF accs up and running..._\n",
    "0. Add TF-IDF matching LFs\n",
    "2. **Conduct TYPE II \"experiment\"!**\n",
    "2. Binarize LFs + run in binary gen model\n",
    "3. Add in simple DDLIB + WS feats from new_features -> run disc. model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_dicts, neg_sets = split_MESH(mesh_entries, target_split_level=1, neg_split_level=1)\n",
    "print len(target_dicts)\n",
    "print np.mean([len(set(td.values())) for td in target_dicts.values()])\n",
    "print len(neg_sets)\n",
    "print np.mean([len(ns) for ns in neg_sets.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LFGen_MESH_exact(target_dictionaries, neg_sets):\n",
    "    LFs = []\n",
    "    for name, td in target_dictionaries.iteritems():\n",
    "        \n",
    "        # Simple exact match LF\n",
    "        def lf(c):\n",
    "            td = target_dictionaries[name]\n",
    "            print td\n",
    "            p  = c.disease.get_span().lower()\n",
    "            if p in td:\n",
    "                return MESH_to_CID[td[p]]\n",
    "            else:\n",
    "                return 0\n",
    "        lf.__name__ = 'LF_MESH_exact_%s' % name\n",
    "        LFs.append(lf)\n",
    "        \n",
    "    for name, ns in neg_sets.iteritems():\n",
    "        \n",
    "        # Simple exact negative match LF\n",
    "        def lf(c):\n",
    "            p = c.disease.get_span().lower()\n",
    "            if p in ns:\n",
    "                return -1\n",
    "            else:\n",
    "                return 0\n",
    "        lf.__name__ = 'LF_MESH_exact_neg_%s' % name\n",
    "        LFs.append(lf)\n",
    "    return LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LF_accuracy(LF, candidates, gold):\n",
    "    correct = 0\n",
    "    labeled = 0\n",
    "    for i,c in enumerate(candidates):\n",
    "        l = LF(c)\n",
    "        if l != 0:\n",
    "            labeled += 1\n",
    "            if l == gold[i,0]:\n",
    "                correct += 1\n",
    "    print \"Number labeled:\\t\", labeled\n",
    "    print \"Correct:\\t\", correct / float(labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_diseases = {}\n",
    "for td in target_dictset_dictionaries.values():\n",
    "    for term, mid in td.iteritems():\n",
    "        all_diseases[term] = mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_MESH(mesh_entries, target_prefixes=['C', 'F'], target_split_level=2, neg_split_level=1):\n",
    "    \"\"\"\n",
    "    Split the MESH entries list into a list of *target dictionaries* and a list of *negative sets*\n",
    "    Each target dictionary maps terms -> MESH IDs\n",
    "    Each negative set just contains terms that are negative matches\n",
    "    \"\"\"\n",
    "    target_dictionaries = defaultdict(dict)\n",
    "    neg_sets            = defaultdict(set)\n",
    "    \n",
    "    for entry in mesh_entries:\n",
    "        mid, tree_nums, terms = entry\n",
    "        for tn in tree_nums:\n",
    "            prefix = tn[0]\n",
    "            path   = tn[1:].split(\".\")\n",
    "            \n",
    "            # Targets\n",
    "            if prefix in target_prefixes:\n",
    "                tag = \"_\".join(path[:target_split_level])\n",
    "                for term in terms:\n",
    "                    target_dictionaries[tag][term] = mid\n",
    "            \n",
    "            # Negative sets\n",
    "            else:\n",
    "                tag = \"_\".join(path[:neg_split_level])\n",
    "                for term in terms:\n",
    "                    neg_sets[tag].add(term)\n",
    "    return target_dictionaries, neg_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_tfidf_MESH_LFs(target_dictionaries, neg_sets):\n",
    "    LFs = []\n",
    "    Ds  = []\n",
    "    for name, td in target_dictionaries.iteritems():\n",
    "        \n",
    "        # Simple exact match LF\n",
    "        def lf(c):\n",
    "            p = c.disease.get_span().lower()\n",
    "            if p in td:\n",
    "                return MESH_to_CID[td[p]]\n",
    "            else:\n",
    "                return 0\n",
    "        lf.__name__ = 'LF_MESH_exact_%s' % name\n",
    "        LFs.append(lf)\n",
    "        \n",
    "    for name, ns in neg_sets.iteritems():\n",
    "        \n",
    "        # Simple exact negative match LF\n",
    "        def lf(c):\n",
    "            p = c.disease.get_span().lower()\n",
    "            if p in ns:\n",
    "                return -1\n",
    "            else:\n",
    "                return 0\n",
    "        lf.__name__ = 'LF_MESH_exact_neg_%s' % name\n",
    "        LFs.append(lf)\n",
    "    return LFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelManager\n",
    "\n",
    "label_manager = LabelManager()\n",
    "L_gold_dev = label_manager.load(session, dev, \"CDR Development Label Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exact dictionary match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LF_exact_MESH_match(c):\n",
    "    p = c.disease.get_span().lower()\n",
    "    if p in diseases:\n",
    "        return MESH_to_CID[diseases[p]]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time LF_accuracy(LF_exact_MESH_match, dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disease_bags = {}\n",
    "for term, mid in diseases.iteritems():\n",
    "    disease_bags[frozenset(re.findall(r'\\w+', term))] = mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LF_bag_MESH_match(c):\n",
    "    bag = frozenset(re.findall(r'\\w+', c.disease.get_span().lower()))\n",
    "    if bag in disease_bags:\n",
    "        return MESH_to_CID[disease_bags[bag]]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time LF_accuracy(LF_bag_MESH_match, dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from entity_norm import CanonDictVectorizer\n",
    "\n",
    "cd_vectorizer = CanonDictVectorizer(diseases, other_phrases=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "disease_phrases = []\n",
    "disease_cids    = []\n",
    "for term, mid in diseases.iteritems():\n",
    "    disease_phrases.append(term)\n",
    "    disease_cids.append(mid)\n",
    "    \n",
    "D = cd_vectorizer.vectorize_phrases(disease_phrases)\n",
    "D\n",
    "\n",
    "def LF_tfidf_MESH_match(c, thresh):\n",
    "    cx = cd_vectorizer.vectorize_phrases([c.disease.get_span()])\n",
    "    m  = (cx * D.T).tocoo()\n",
    "    if m.data.shape[0] > 0 and m.data.max() > thresh:\n",
    "        return MESH_to_CID[disease_cids[m.col[m.data.argmax()]]]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LF_tfidf_MESH_match(c, thresh):\n",
    "    cx = cd_vectorizer.vectorize_phrases([c.disease.get_span()])\n",
    "    m  = (cx * D.T).tocoo()\n",
    "    if m.data.shape[0] > 0 and m.data.max() > thresh:\n",
    "        return MESH_to_CID[disease_cids[m.col[m.data.argmax()]]]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LF_tfidf_MESH_match_0(c):\n",
    "    cx = cd_vectorizer.vectorize_phrases([c.disease.get_span()])\n",
    "    m  = (cx * D.T).tocoo()\n",
    "    if m.data.shape[0] > 0:\n",
    "        return MESH_to_CID[disease_cids[m.col[m.data.argmax()]]]\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time LF_accuracy(LF_tfidf_MESH_match_0, dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LF_tfidf_MESH_match_05(c):\n",
    "    return LF_tfidf_MESH_match(c, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time LF_accuracy(LF_tfidf_MESH_match_05, dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LF_tfidf_MESH_match_08(c):\n",
    "    return LF_tfidf_MESH_match(c, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time LF_accuracy(LF_tfidf_MESH_match_08, dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LF_tfidf_MESH_match_1(c):\n",
    "    return LF_tfidf_MESH_match(c, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time LF_accuracy(LF_tfidf_MESH_match_1, dev, L_gold_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.viewer import SentenceNgramViewernceNgramViewerenceNgramViewer\n",
    "\n",
    "sv = SentenceNgramViewer(, session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatically Creating Features\n",
    "Recall that our goal is to distinguish between true and false mentions of chemical-disease relations. To train a model for this task, we first embed our `ChemicalDisease` candidates in a feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import FeatureManager\n",
    "\n",
    "feature_manager = FeatureManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a new feature set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time F_train = feature_manager.create(session, train, 'Train Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OR** if we've already created one, we can simply load as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time F_train = feature_manager.load(session, train, 'Train Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the returned matrix is a special subclass of the `scipy.sparse.csr_matrix` class, with some special features which we demonstrate below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F_train.get_candidate(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F_train.get_key(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Labeling Functions\n",
    "Labeling functions are a core tool of data programming. They are heuristic functions that aim to classify candidates correctly. Their outputs will be automatically combined and denoised to estimate the probabilities of training labels for the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from lf_terms import *\n",
    "from snorkel.lf_helpers import get_left_tokens, get_right_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also load some publicly-available biomedical dictionaries, which we will leverage in some of our LFs below as a source of weak supervision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "umls_dict              = load_umls_dictionary()\n",
    "chemicals              = load_chemdner_dictionary()\n",
    "abbrv2text, text2abbrv = load_specialist_abbreviations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document-Level Labeling Functions\n",
    "We start with some labeling functions that label candidates based on document-level features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.lf_helpers import get_doc_candidate_spans\n",
    "\n",
    "def LF_undefined_abbreviation(c):\n",
    "    '''Candidate is a known abbreviation, but no corresponding full name in document'''\n",
    "    doc_spans = get_doc_candidate_spans(c)\n",
    "    phrase = c[0].get_span().lower()\n",
    "    mentions = set([s.get_span().lower() for s in doc_spans])\n",
    "    if len(phrase) > 1 and phrase in abbrv2text and not set(abbrv2text[phrase].keys()).intersection(mentions):\n",
    "        return -1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence-Level Labeling Functions\n",
    "We also include some labeling functions that label candidates based on sentence-level features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.lf_helpers import get_sent_candidate_spans\n",
    "\n",
    "def LF_contiguous_mentions(c):\n",
    "    '''Contiguous candidates are likely wrong'''\n",
    "    neighbor_spans = get_sent_candidate_spans(c)\n",
    "    start, end = c[0].get_word_start(), c[0].get_word_end()\n",
    "    for s in neighbor_spans:\n",
    "        if s.get_word_end() + 1 == start or s.get_word_start() - 1 == end:\n",
    "            return -1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mention-Level Labeling Functions\n",
    "We now define a number of labeling functions that label candidates based on attributes related to the mention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.lf_helpers import get_left_tokens, get_right_tokens\n",
    "\n",
    "def LF_tumors_growths(c):\n",
    "    phrase = \" \".join(c[0].get_attrib_tokens('lemmas'))\n",
    "    return 1 if re.search(\"^(\\w* ){0,2}(['] )*(tumor|tumour|polyp|pilomatricoma|cyst|lipoma)$\", phrase) else 0\n",
    "\n",
    "def LF_cancer(c):\n",
    "    '''<TYPE> cancer'''\n",
    "    phrase = \" \".join(c[0].get_attrib_tokens('lemmas'))\n",
    "    return 1 if re.search(\"\\w* cancer\",phrase) else 0\n",
    "\n",
    "def LF_disease_syndrome(c):\n",
    "    '''<TYPE> disease or <TYPE> syndrome'''\n",
    "    phrase = \" \".join(c[0].get_attrib_tokens('lemmas'))\n",
    "    return 1 if re.search(\"\\w* (disease|syndrome)+\",phrase) else 0\n",
    "\n",
    "def LF_indicators(c):\n",
    "    '''Indicator words'''\n",
    "    return 1 if \" \".join(c[0].get_attrib_tokens()).lower() in indicators else 0\n",
    "\n",
    "def LF_common_disease(c):\n",
    "    '''Common disease'''\n",
    "    return 1 if \" \".join(c[0].get_attrib_tokens()).lower() in common_disease else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For a few more examples of LFs of this style that we'll use, see [Disease_Tagging_Tutorial_LFs.py](Disease_Tagging_Tutorial_LFs.py).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionary Labeling Functions\n",
    "We can use existing dictionaries for distant supervision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LF_SNOWMED_CT_sign_or_symptom(c):\n",
    "    return 1 if c[0].get_span() in umls_dict[\"snomedct\"][\"sign_or_symptom\"] else 0\n",
    "\n",
    "def LF_SNOWMED_CT_disease_or_syndrome(c):\n",
    "    return 1 if c[0].get_span() in umls_dict[\"snomedct\"][\"disease_or_syndrome\"] else 0\n",
    "\n",
    "def LF_MESH_disease_or_syndrome(c):\n",
    "    return 1 if c[0].get_span() in umls_dict[\"mesh\"][\"disease_or_syndrome\"] else 0\n",
    "\n",
    "def LF_MESH_sign_or_symptom(c):\n",
    "    return 1 if c[0].get_span() in umls_dict[\"mesh\"][\"sign_or_symptom\"] else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative Labeling Functions\n",
    "When writing labeling functions, it is important to provide negative supervision in addition to positive supervision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LF_organs(c):\n",
    "    phrase = \" \".join(c[0].get_attrib_tokens()).lower()\n",
    "    return -1 if phrase in organs else 0      \n",
    "\n",
    "def LF_chemical_name(c):\n",
    "    phrase = \" \".join(c[0].get_attrib_tokens())\n",
    "    return -1 if phrase in chemicals and not phrase.isupper() else 0\n",
    "\n",
    "def LF_bodysym(c):\n",
    "    phrase = \" \".join(c[0].get_attrib_tokens()).lower()\n",
    "    return -1 if phrase in bodysym else 0  \n",
    "\n",
    "def LF_protein_chemical_abbrv(c):\n",
    "    '''Gene/protein/chemical name'''\n",
    "    lemma = \" \".join(c[0].get_attrib_tokens('lemmas'))\n",
    "    return -1 if re.search(\"\\d+\",lemma) else 0\n",
    "\n",
    "def LF_base_pair_seq(c): \n",
    "    lemma = \" \".join(c[0].get_attrib_tokens('lemmas'))\n",
    "    return -1 if re.search(\"^[GACT]{2,}$\",lemma) else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For a few more examples of LFs of this style that we'll use, see [Disease_Tagging_Tutorial_LFs.py](Disease_Tagging_Tutorial_LFs.py).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We maintain a list of all LFs for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Disease_Tagging_Tutorial_LFs import *\n",
    "\n",
    "LFs_doc = [LF_undefined_abbreviation]\n",
    "\n",
    "LFs_sent = [LF_contiguous_mentions]\n",
    "\n",
    "LFs_mention = [LF_tumors_growths,\n",
    "               LF_cancer,\n",
    "               LF_disease_syndrome,\n",
    "               LF_indicators,\n",
    "               LF_common_disease,\n",
    "               LF_common_disease_acronyms,\n",
    "               LF_deficiency_of,\n",
    "               LF_positive_indicator,\n",
    "               LF_left_positive_argument,\n",
    "               LF_right_negative_argument,\n",
    "               LF_medical_afixes,\n",
    "               LF_adj_diseases\n",
    "              ]\n",
    "\n",
    "LFs_dicts =  [LF_SNOWMED_CT_sign_or_symptom,\n",
    "              LF_SNOWMED_CT_disease_or_syndrome,\n",
    "              LF_MESH_disease_or_syndrome,\n",
    "              LF_MESH_sign_or_symptom\n",
    "            ]\n",
    "\n",
    "LFs_false = [LF_chemical_name,\n",
    "             LF_organs,\n",
    "             LF_bodysym,\n",
    "             LF_protein_chemical_abbrv,\n",
    "             LF_base_pair_seq,\n",
    "             LF_too_vague,\n",
    "             LF_neg_surfix,\n",
    "             LF_non_common_disease,\n",
    "             LF_non_disease_acronyms,\n",
    "             LF_pos_in,\n",
    "             LF_gene_chromosome_link,\n",
    "             LF_right_window_incomplete,\n",
    "             LF_negative_indicator\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Labeling Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we construct a `CandidateLabeler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelManager\n",
    "\n",
    "label_manager = LabelManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we run the `CandidateLabeler` to to apply the labeling functions to the training `CandidateSet`.  We'll start with some of our labeling functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LFs = LFs_mention + LFs_dicts + LFs_false\n",
    "%time L_train = label_manager.create(session, train, 'LF Labels', f=LFs)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OR** load if we've already created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time L_train = label_manager.load(session, train, 'LF Labels')\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add or rerun a single labeling function (or more!) with the below command. Note that we set the argument `expand_key_set` to `True` to indicate that the set of matrix columns should be allowed to expand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LFs_2   = LFs_doc + LFs_sent\n",
    "L_train = label_manager.update(session, train, 'LF Labels', True, f=LFs_2)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view statistics about the resulting label matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_train.lf_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Generative Model\n",
    "We estimate the accuracies of the labeling functions without supervision. Specifically, we estimate the parameters of a `NaiveBayes` generative model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "\n",
    "gen_model = GenerativeModel()\n",
    "gen_model.train(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_model.save(session, 'Generative Params')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply the generative model to the training candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Discriminative Model\n",
    "We use the estimated probabilites to train a discriminative model that classifies each `Candidate` as a true or false mention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import LogReg\n",
    "\n",
    "disc_model = LogReg()\n",
    "disc_model.train(F_train, train_marginals, n_iter=5000, rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "disc_model.w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time disc_model.save(session, \"Discriminative Params\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on the Development `CandidateSet`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create features for the development set.\n",
    "\n",
    "Note that we use the training features feature set, because those are the only features for which we have learned parameters. Features that were not encountered during training, e.g., a token that does not appear in the training set, are ignored, because we do not have any information about them.\n",
    "\n",
    "To do so with the `FeatureManager`, we call update with the new `CandidateSet`, the name of the training `AnnotationKeySet`, and the value `False` for the parameter `extend_key_set` to indicate that the `AnnotationKeySet` should not be expanded with new `Feature` keys encountered during processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time F_dev = feature_manager.update(session, dev, 'Train Features', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OR** if we've already created one, we can simply load as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time F_dev = feature_manager.load(session, dev, 'Train Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we load the development set labels and gold candidates we made in Part III."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "L_gold_dev = label_manager.load(session, dev, \"CDR Development Labels -- Gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gold_dev_set = session.query(CandidateSet).filter(CandidateSet.name == 'CDR Development Candidates -- Gold').one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can evaluate the discriminative model on the development set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tp, fp, tn, fn = disc_model.score(F_dev, L_gold_dev, gold_dev_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing Examples\n",
    "After evaluating on the development `CandidateSet`, the labeling functions can be modified. Try changing the labeling functions to improve performance. You can view the true positives, false positives, true negatives, and false negatives using the `Viewer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.viewer import SentenceNgramViewer\n",
    "\n",
    "# NOTE: This if-then statement is only to avoid opening the viewer during automated testing of this notebook\n",
    "# You should ignore this!\n",
    "import os\n",
    "if 'CI' not in os.environ:\n",
    "    sv = SentenceNgramViewer(tp, session, annotator_name=\"Tutorial Part IV User\")\n",
    "else:\n",
    "    sv = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, in Part V, we will test our model on the test `CandidateSet`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
