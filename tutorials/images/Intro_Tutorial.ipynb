{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ[\"SNORKELHOME\"] = \"/afs/cs.stanford.edu/u/paroma/snorkel_new/babble_snorkel/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Visualize Dataset\n",
    "First, we load the dataset and associated bounding box objects and labels.\n",
    "Note that in some cases, the resulting images from the query will be incorrectly labeled. THis is because the ground truth also comes from a crodsourced setting where relations in the image are described, and therefore prone to error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make sure to run `unzip tutorial_data` before running this cell!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import DataLoader\n",
    "loader = DataLoader()\n",
    "\n",
    "loader.show_examples(annotated=False, label=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Primitives\n",
    "Since we cannot check relations in the images directly by writing labeling functions over the primitives, we first extract a set of  \"primitives\" from the images that are easily interpretable.\n",
    "\n",
    "In this case, we use information about the objects in the data such as their labels, their positions and their size.  We show how we develop simple primitives that are based on the labels of the different objects and include the more complex primitives in `primitive_helpers.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Membership-based Primitives\n",
    "Check whether certain objects appear in the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_bike(object_names):\n",
    "    if ('cycle' in object_names) or ('bike' in object_names) or ('bicycle' in object_names):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_human(object_names):\n",
    "    if (('person' in object_names) or ('woman' in object_names) or ('man' in object_names)) and (('bicycle' in object_names) or 'bicycles' in object_names):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_road(object_names):\n",
    "    if ('road' in object_names) or ('street' in object_names) or ('concrete' in object_names):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_cars(object_names):\n",
    "    if ('car' in object_names) or ('cars' in object_names) or ('bus' in object_names) or ('buses' in object_names) or ('truck' in object_names) or ('trucks' in object_names):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Object Relationship Based Primitives\n",
    "These look at the relation among the bikes and the people in the images. These include checking the relative:\n",
    "* number of bikes vs people\n",
    "* position of bikes vs people\n",
    "* size of bikes vs people\n",
    "\n",
    "Code for the development of these primitives is included in the file `primitive_helpers.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from primitive_helpers import *\n",
    "def create_primitives(loader):\n",
    "    m = 7\n",
    "    primitive_mtx = np.zeros((loader.train_num,m))\n",
    "\n",
    "    for i in xrange(loader.train_num):\n",
    "        primitive_mtx[i,0] = has_human(loader.train_object_names[i])\n",
    "        primitive_mtx[i,1] = has_road(loader.train_object_names[i])\n",
    "        primitive_mtx[i,2] = has_cars(loader.train_object_names[i])\n",
    "        primitive_mtx[i,3] = has_bike(loader.train_object_names[i])\n",
    "\n",
    "        primitive_mtx[i,4] = bike_human_distance(loader.train_object_names[i], \n",
    "                                                 loader.train_object_x[i], \n",
    "                                                 loader.train_object_y[i])\n",
    "\n",
    "        area = np.multiply(loader.train_object_height[i], loader.train_object_width[i])\n",
    "        primitive_mtx[i,5] = bike_human_size(loader.train_object_names[i], area)\n",
    "        primitive_mtx[i,6] = bike_human_nums(loader.train_object_names[i])\n",
    "        \n",
    "    P = PrimitiveObject()\n",
    "    P.save_primitive_matrix(primitive_mtx)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assign and Name Primitives**\n",
    "We assign the primitives and name them according to the variables we will use to refer to them in the heuristic functions we develop next. \n",
    "\n",
    "For example, `primitive_mtx[i,0]` is referred to as `has_human`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = create_primitives(loader)\n",
    "primitive_names = ['has_human', 'has_road', 'has_cars', 'has_bike', \n",
    "                   'bike_human_distance', 'bike_human_size', 'bike_human_num']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic Functions\n",
    "We now develop heuristic functions that take different primitives in as inputs and apply a label based on the value of those primitives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_street(has_human, has_road):\n",
    "    if has_human >= 1: \n",
    "        if has_road >= 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    return 0\n",
    "\n",
    "def LF_vehicles(has_human, has_cars):\n",
    "    if has_human >= 1: \n",
    "        if has_cars >= 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    return 0\n",
    "\n",
    "def LF_distance(has_human, has_bike, bike_human_distance):\n",
    "    if has_human >= 1:\n",
    "        if has_bike >= 1: \n",
    "            if bike_human_distance <= np.sqrt(8):\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def LF_size(has_human, has_bike, bike_human_size):\n",
    "    if has_human >= 1:\n",
    "        if has_bike >= 1: \n",
    "            if bike_human_size <= 1000:\n",
    "                return -1\n",
    "            else:\n",
    "                return 0\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "    \n",
    "def LF_number(has_human, has_bike, bike_human_num):\n",
    "    if has_human >= 1:\n",
    "        if has_bike >= 1: \n",
    "            if bike_human_num >= 2:\n",
    "                return 1\n",
    "            if bike_human_num >= 1:\n",
    "                return 0\n",
    "            if bike_human_num >= 0:\n",
    "                return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assign Heuristic Functions**\n",
    "\n",
    "We create a list of the functions we used in `L_names` and apply the heuristic functions to the appropriate primitives to generate `L`, a _labeling matrix_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_names = [LF_street,LF_vehicles,LF_distance,LF_size,LF_number]\n",
    "\n",
    "L = np.zeros((len(L_names),loader.train_num))\n",
    "for i in xrange(loader.train_num):\n",
    "    L[0,i] = LF_street(P.primitive_mtx[i,0],P.primitive_mtx[i,1])\n",
    "    L[1,i] = L_names[1](P.primitive_mtx[i,0],P.primitive_mtx[i,2])\n",
    "    L[2,i] = L_names[2](P.primitive_mtx[i,0],P.primitive_mtx[i,3], P.primitive_mtx[i,4])\n",
    "    L[3,i] = L_names[3](P.primitive_mtx[i,0],P.primitive_mtx[i,3], P.primitive_mtx[i,5])\n",
    "    L[4,i] = L_names[4](P.primitive_mtx[i,0],P.primitive_mtx[i,3], P.primitive_mtx[i,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate and Show Accuracy and Coverage of Heuristic Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = float(loader.train_num)\n",
    "\n",
    "stats_table = np.zeros((5,2))\n",
    "for i in range(5):\n",
    "    stats_table[i,1] = np.sum(L[i,:] == loader.train_ground)/float(np.sum(L[i,:] != 0))\n",
    "    stats_table[i,0] = np.sum(L[i,:] != 0)/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "stats_table = pd.DataFrame(stats_table, index = [i.__name__ for i in L_names], columns = [\"Coverage\", \"Accuracy\"])\n",
    "stats_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "from scipy import sparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "L_train = sparse.csr_matrix(L.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Majority Vote**\n",
    "\n",
    "To get a sense of how well our heuristic functions are, we calcuate the accuracy of the training set labels if we took the majority vote label for each data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_labels = np.sign(np.sum(L.T,1))\n",
    "print 'Coverage of Majority Vote on Train Set: ', np.sum(np.sign(np.sum(np.abs(L.T),1)) != 0)/float(loader.train_num)\n",
    "print 'Accuracy of Majority Vote on Train Set: ', np.sum(mv_labels == loader.train_ground)/float(loader.train_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generative Model**\n",
    "We assume that the heuristic functions are conditionally independent of the true label and train the generative model using the labels assigned by the heuristic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model = GenerativeModel()\n",
    "\n",
    "gen_model.train(L.T, epochs=100, decay=0.95, step_size= 0.01/ L.shape[1], reg_param=1e-6)\n",
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Probabilistic Label Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_table = gen_model.learned_lf_stats()\n",
    "complete_stats = pd.DataFrame(np.hstack((learned_table.as_matrix()[:,0:2], stats_table.as_matrix()[:,[1,0]])), \n",
    "                              index = [i.__name__ for i in L_names], \n",
    "                              columns=['Learn. Acc.', 'Learn. Cov.', 'Emp. Acc.', 'Emp. Cov.'])\n",
    "complete_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 2 * (train_marginals > 0.9) - 1\n",
    "print 'Coverage of Generative Model on Train Set:', np.sum(train_marginals != 0.5)/float(len(train_marginals))\n",
    "print 'Accuracy of Generative Model on Train Set:', np.mean(labels == loader.train_ground)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
