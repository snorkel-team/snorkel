{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: `Candidate` Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If necessary:\n",
    "import os\n",
    "os.remove('snorkel.db');\n",
    "os.system('cp snorkel.db\\ corpus snorkel.db');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.environ['SNORKELHOME'] + '/tutorials/tables/')\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Training `Corpus`\n",
    "\n",
    "First, we will load the `Corpus` that we preprocessed in Part I:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus (Hardware Training) contains 78 Documents\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Corpus\n",
    "from snorkel.utils import get_ORM_instance\n",
    "\n",
    "corpus = get_ORM_instance(Corpus, session, 'Hardware Training')\n",
    "print \"%s contains %d Documents\" % (corpus, len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a `Candidate` Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Part_Temp = candidate_subclass('Part_Temp', ['part','temp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing a basic `CandidateExtractor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from snorkel.matchers import DictionaryMatch\n",
    "\n",
    "# from hardware_utils import load_extended_parts_dict\n",
    "# gold_file ='data/hardware/hardware_gold.csv'\n",
    "# parts_dict = load_extended_parts_dict(gold_file) # NOTE: this include A/B/C/-16/-25/-40 \n",
    "# print \"Loaded %d part numbers.\" % len(parts_dict)\n",
    "# parts_matcher = DictionaryMatch(d=parts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.matchers import RegexMatchSpan, Union\n",
    "\n",
    "eeca_matcher = RegexMatchSpan(rgx='([b]{1}[abcdefklnpqruyz]{1}[\\swxyz]?[0-9]{3,5}[\\s]?[A-Z\\/]{0,5}[0-9]?[A-Z]?([-][A-Z0-9]{1,7})?([-][A-Z0-9]{1,2})?)')\n",
    "jedec_matcher = RegexMatchSpan(rgx='([123]N\\d{3,4}[A-Z]{0,5}[0-9]?[A-Z]?)')\n",
    "jis_matcher = RegexMatchSpan(rgx='(2S[abcdefghjkmqrstvz]{1}[\\d]{2,4})')\n",
    "others_matcher = RegexMatchSpan(rgx='((NSVBC|SMBT|MJ|MJE|MPS|MRF|RCA|TIP|ZTX|ZT|TIS|TIPL|DTC|MMBT|PZT){1}[\\d]{2,4}[A-Z]{0,3}([-][A-Z0-9]{0,6})?([-][A-Z0-9]{0,1})?)')\n",
    "parts_matcher = Union(eeca_matcher, jedec_matcher, jis_matcher, others_matcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.matchers import RegexMatchSpan\n",
    "\n",
    "temp_matcher = RegexMatchSpan(rgx=r'-[5-7][05]', longest_match_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# from hardware_utils import get_gold_dict\n",
    "# from collections import defaultdict\n",
    "\n",
    "# gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "# gold_parts = get_gold_dict(gold_file, doc_on=True, part_on=True, val_on=False)\n",
    "# gold_parts_by_doc = defaultdict(set)\n",
    "# for part in gold_parts:\n",
    "#     gold_parts_by_doc[part[0]].add(part[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print len(gold_parts_by_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from snorkel.models import Corpus\n",
    "# from snorkel.utils import get_ORM_instance\n",
    "# from hardware_utils import OmniNgramsPart\n",
    "# from snorkel.matchers import RegexMatchSpan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# group_matcher = RegexMatchSpan(rgx=r'^(A|B|C|-?16|-?25|-?40)$', ignore_case=False)\n",
    "\n",
    "# corpus = get_ORM_instance(Corpus, session, 'Hardware')\n",
    "# part_ngrams_2 = OmniNgramsPart(n_max=3)\n",
    "# parts_by_doc = defaultdict(set)\n",
    "# groups_by_doc = defaultdict(set)\n",
    "# for doc in corpus.documents:\n",
    "#     for tc in part_ngrams_2.apply(doc):\n",
    "#         if parts_matcher.f(tc):\n",
    "#             parts_by_doc[tc.parent.document.name.upper()].add(tc.get_span())\n",
    "#         if group_matcher._f(tc):\n",
    "#             if \n",
    "#             groups_by_doc[tc.parent.document.name.upper()].add(tc.get_span())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print set(parts_by_doc.keys()).difference(set(gold_parts_by_doc.keys()))\n",
    "# print set(gold_parts_by_doc.keys()).difference(set(parts_by_doc.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print len(gold_parts_by_doc)\n",
    "# print len(parts_by_doc)\n",
    "# print gold_parts_by_doc['PJECS00521-1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print groups_by_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from itertools import chain\n",
    "# from pprint import pprint\n",
    "\n",
    "# gold_parts = [x for x in chain.from_iterable(gold_parts_by_doc.values())]\n",
    "# found_parts = [x for x in chain.from_iterable(parts_by_doc.values())]\n",
    "# print len(gold_parts)\n",
    "# print len(found_parts)\n",
    "# print set(gold_parts).difference(set(found_parts))\n",
    "# missed = []\n",
    "# for doc in gold_parts_by_doc.keys():\n",
    "#     for part in gold_parts_by_doc[doc]:\n",
    "#         if part not in parts_by_doc[doc]:\n",
    "#              missed.append((doc, part))\n",
    "# print len(missed)\n",
    "# pprint(missed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.throttlers import PartThrottler\n",
    "\n",
    "part_throttler = PartThrottler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: replace dictionary-based parts_by_doc with first-pass parts_by_doc\n",
    "from hardware_utils import get_gold_dict\n",
    "from collections import defaultdict\n",
    "\n",
    "gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "gold_parts = get_gold_dict(gold_file, doc_on=True, part_on=True, val_on=False)\n",
    "parts_by_doc = defaultdict(set)\n",
    "for part in gold_parts:\n",
    "    parts_by_doc[part[0]].add(part[1]) # TODO: change gold_parts to work with namedTuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from hardware_utils import OmniNgramsPart, OmniNgramsTemp\n",
    "\n",
    "part_ngrams = OmniNgramsPart(parts_by_doc=parts_by_doc, n_max=3)\n",
    "temp_ngrams = OmniNgramsTemp(n_max=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import CandidateExtractor\n",
    "\n",
    "ce = CandidateExtractor(Part_Temp, \n",
    "                        [part_ngrams, temp_ngrams], \n",
    "                        [parts_matcher, temp_matcher], \n",
    "                        part_throttler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the `CandidateExtractor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========================================] 101%\n",
      "\n",
      "CPU times: user 42.8 s, sys: 340 ms, total: 43.1 s\n",
      "Wall time: 43.5 s\n",
      "Candidate Set (Hardware Training Candidates) contains 22335 Candidates\n"
     ]
    }
   ],
   "source": [
    "%time train = ce.extract(corpus.documents, 'Hardware Training Candidates', session)\n",
    "print \"%s contains %d Candidates\" % (train, len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part_Temp(Span(\"BC550\", parent=18435, chars=[32,36], words=[8,8]), ImplicitSpan(\"-65\", parent=100729, words=[0,0], position=[0]))\n",
      "Part_Temp(ImplicitSpan(\"BC546BCTA\", parent=18435, words=[0,0], position=[0]), ImplicitSpan(\"-65\", parent=100729, words=[0,0], position=[0]))\n",
      "Part_Temp(ImplicitSpan(\"BC546ATA\", parent=18435, words=[0,0], position=[1]), ImplicitSpan(\"-65\", parent=100729, words=[0,0], position=[0]))\n"
     ]
    }
   ],
   "source": [
    "for c in train[:3]:\n",
    "    print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "# from snorkel.utils import ProgressBar\n",
    "\n",
    "# def get_candidate_id(c):\n",
    "#     return c.part.get_stable_id() + c.temp.get_stable_id()\n",
    "\n",
    "# seen = defaultdict(int)\n",
    "# pb = ProgressBar(len(train))\n",
    "# for i, c in enumerate(train):\n",
    "#     pb.bar(i)\n",
    "#     seen[get_candidate_id(c)] += 1\n",
    "#     if seen[get_candidate_id(c)] == 2:\n",
    "#         import pdb; pdb.set_trace()\n",
    "# pb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print type(train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print len(train) == len(set([c for c in train]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the extracted candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "session.add(train)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reloading the candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate Set (Hardware Training Candidates) contains 22335 Candidates\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "from snorkel.utils import get_ORM_instance\n",
    "\n",
    "train = get_ORM_instance(CandidateSet, session, 'Hardware Training Candidates')\n",
    "print \"%s contains %d Candidates\" % (train, len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeating for development and test corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Candidates from Corpus (Hardware Development)\n",
      "[==========================================] 105%\n",
      "\n",
      "CPU times: user 15.7 s, sys: 84 ms, total: 15.8 s\n",
      "Wall time: 16.3 s\n",
      "Candidate Set (Hardware Development Candidates) contains 7914 Candidates\n"
     ]
    }
   ],
   "source": [
    "for corpus_name in ['Hardware Development']:\n",
    "    corpus = get_ORM_instance(Corpus, session, corpus_name)\n",
    "    print \"Extracting Candidates from %s\" % corpus\n",
    "    %time candidates = ce.extract(corpus.documents, corpus_name + ' Candidates', session)\n",
    "    session.add(candidates)\n",
    "    print \"%s contains %d Candidates\" % (candidates, len(candidates))\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train = get_ORM_instance(Corpus, session, 'Hardware Training')\n",
    "# dev = get_ORM_instance(Corpus, session, 'Hardware Development')\n",
    "# test = get_ORM_instance(Corpus, session, 'Hardware Test')\n",
    "# trainies = [d.name for d in train.documents]\n",
    "# len(trainies)\n",
    "# for d in test.documents:\n",
    "#     if d.name in trainies:\n",
    "#         print 'YES!'\n",
    "# # for d in test.documents[:10]: print d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEMPORARY - Assessing Total Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hardware_utils import entity_level_total_recall\n",
    "from snorkel.utils import get_ORM_instance\n",
    "\n",
    "train = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Training Candidates').one()\n",
    "dev = session.query(CandidateSet).filter(\n",
    "    CandidateSet.name == 'Hardware Development Candidates').one()\n",
    "total_set = set([])\n",
    "for c in train:\n",
    "    total_set.add(c)\n",
    "for c in dev:\n",
    "    total_set.add(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part_Temp(ImplicitSpan(\"BC858C\", parent=88990, words=[2,4], position=[11]), ImplicitSpan(\"-65\", parent=88993, words=[0,0], position=[0]))\n"
     ]
    }
   ],
   "source": [
    "print list(total_set)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22335\n",
      "22335\n",
      "7914\n",
      "7914\n",
      "30249\n"
     ]
    }
   ],
   "source": [
    "print len(train)\n",
    "train_set = set([c for c in train])\n",
    "print len(train_set)\n",
    "\n",
    "print len(dev)\n",
    "dev_set = set([c for c in dev])\n",
    "print len(dev_set)\n",
    "\n",
    "print len(total_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing candidates...\n",
      "[====================                    ] 48%"
     ]
    }
   ],
   "source": [
    "import os\n",
    "gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "(tp, fp, fn) = entity_level_total_recall(total_set, gold_file, 'stg_temp_min', relation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hardware_utils import get_gold_dict\n",
    "gold_file = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "gold_attrib = 'stg_temp_min'\n",
    "gold = gold_dict = get_gold_dict(gold_file, gold_attrib)\n",
    "print len(gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "gold_dict_by_doc = defaultdict(set)\n",
    "for g in gold_dict:\n",
    "    gold_dict_by_doc[g[0]].add(g)\n",
    "print sum([len(gold_dict_by_doc[g]) for g in gold_dict_by_doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from snorkel.utils import ProgressBar\n",
    "# target = sorted(list(fn))[-1]\n",
    "# print target\n",
    "# print \"-------------------------------\"\n",
    "# pb = ProgressBar(len(candidates))\n",
    "# for i, c in enumerate(list(candidates)[:]):\n",
    "#     pb.bar(i)\n",
    "#     if (c.part.parent.document.name.upper() == target[0].upper())\n",
    "#         and c.part.get_span().upper() == target[1].upper()):\n",
    "#         print c\n",
    "# pb.close()\n",
    "# print len(tp)\n",
    "# for c in sorted(list(tp))[:5]:\n",
    "#     print c\n",
    "# print \"-------------------------------\"\n",
    "# print len(fn)\n",
    "# for c in sorted(list(fn))[:50]:\n",
    "#     print c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from hardware_utils import part_error_analysis\n",
    "\n",
    "# for c in total_set:\n",
    "#     if c.part.parent.document.name.upper()=='BC546-D' and c.part.get_span() == 'BC547':\n",
    "#         part_error_analysis(c)\n",
    "#         import pdb; pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# corpus = session.query(Corpus).filter(Corpus.name == 'Hardware').one()\n",
    "\n",
    "# for doc in corpus.documents:\n",
    "#     if doc.name == 'PNJIS00254-1':\n",
    "#         d = doc\n",
    "#         break\n",
    "# print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for phrase in d.phrases:\n",
    "#     if '55' in phrase.words:\n",
    "#         p = phrase\n",
    "#         print p.cell\n",
    "#         import pdb; pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# candies = sorted(candidates, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from hardware_utils import count_hardware_labels\n",
    "\n",
    "# filename = os.environ['SNORKELHOME'] + '/tutorials/tables/data/hardware/hardware_gold.csv'\n",
    "# %time count_hardware_labels(candidates, filename, attrib='stg_temp_min', attrib_class='temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('cp snorkel.db\\ candidates snorkel.db');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candidates_by_doc = defaultdict(int)\n",
    "for c in total_set:\n",
    "    candidates_by_doc[c.part.parent.document.name] += 1\n",
    "print sum(sorted(candidates_by_doc.values())[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEMPORARY - Return to Normalcy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If necessary\n",
    "import os\n",
    "os.system('cp snorkel.db snorkel.db\\ candidates');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, in Part 3, we will load `Labels` for each of our `Candidates` so that we can evaluate performance."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
