{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"imgs/logo.jpg\" width=\"50px\" style=\"margin-right:10px\">\n",
    "# Snorkel Workshop: Extracting Spouse Relations <br> from the News\n",
    "## Part 2: Writing  Labeling Functions\n",
    "\n",
    "In Snorkel, our primary interface through which we provide training signal to the end extraction model we are training is by writing **labeling functions (LFs)** (as opposed to hand-labeling massive training sets).  We'll go through some examples for our spouse extraction task below.\n",
    "\n",
    "A labeling function isn't anything special. It's just a Python function that accepts a `Candidate` as the input argument and returns `1` if it says the `Candidate` should be marked as true, `-1` if it says the `Candidate` should be marked as false, and `0` if it doesn't know how to vote and abstains. In practice, many labeling functions are unipolar: it labels only `1`s and `0`s, or it labels only `-1`s and `0`s.\n",
    "\n",
    "Recall that our goal is to ultimately train a high-performance classification model that predicts which of our `Candidate`s are true mentions of spouse relations.  It turns out that we can do this by writing potentially low-quality labeling functions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Connect to the database backend and initalize a Snorkel session\n",
    "from lib.init import *\n",
    "from lib.scoring import *\n",
    "from lib.lf_factories import *\n",
    "\n",
    "from snorkel.lf_helpers import test_LF\n",
    "from snorkel.annotations import load_gold_labels\n",
    "from snorkel.lf_helpers import (\n",
    "    get_left_tokens, get_right_tokens, get_between_tokens,\n",
    "    get_text_between, get_tagged_text,\n",
    ")\n",
    "\n",
    "# initialize our candidate type definition\n",
    "Spouse = candidate_subclass('Spouse', ['person1', 'person2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Background\n",
    "\n",
    "## A. Preprocessing the Database\n",
    "\n",
    "In a real application, there is a lot of data preparation, parsing, and database loading that needs to be completed before we dive into writing labeling functions. Here we've pre-generated a database instance for you. All _candidates_ and _gold labels_ (i.e., human-generated labels) are queried from this database for use in the the tutorial. \n",
    "\n",
    "See our preprocessing tutorial <a href=\"Workshop_5_Advanced_Preprocessing.ipynb\">Workshop 5 Advanced Preprocessing</a> for more details on how this database is built.\n",
    "\n",
    "## B. Using a _Development Set_ of Human-labeled Data\n",
    "\n",
    "In our setting, we will use the phrase _development set_ to refer to a set of examples (here, a subset of our training set) which we label by hand and use to help us develop and refine labeling functions.  Unlike the _test set_, which we do not look at and use for final evaluation, we can inspect the development set while writing labeling functions. This is a list of `{-1,1}` labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Data Exploration\n",
    "\n",
    "How do we come up with good keywords and patterns to encode as labeling functions? One way is to manually explore our training data. Here we load a subset of our training candidates into a `SentenceNgramViewer` object to examine candidates in their parent context. Our goal is to build an intuition for patterns and keywords that are predictive of a candidate's true label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.viewer import SentenceNgramViewer\n",
    "\n",
    "# load our list of training & development candidates\n",
    "train_cands = session.query(Candidate).filter(Candidate.split == 0).all()\n",
    "dev_cands   = session.query(Candidate).filter(Candidate.split == 1).all()\n",
    "\n",
    "SentenceNgramViewer(train_cands[0:500], session, n_per_page=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Labeling Function Metrics\n",
    "\n",
    "### 1. Coverage\n",
    "One simple metric we can compute quickly is our _coverage_, the number of candidates labeled by our LF, on our training set (or any other set).\n",
    "\n",
    "### 2. Precision / Recall / F1\n",
    "If we have gold labeled data, we can also compute standard precision, recall, and F1 metrics for the output of a single labeling function. These metrics are computed over 4 _error buckets_: _True Positives_ (tp), _False Positives_ (fp), _True Negatives_ (tn), and _False Negatives_ (fn).\n",
    "\n",
    "\\begin{equation*}\n",
    "precision = \\frac{tp}{(tp + fp)}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "recall = \\frac{tp}{(tp + fn)}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "F1 = 2 \\cdot \\frac{ (precision \\cdot recall)}{(precision + recall)}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Labeling Functions\n",
    "\n",
    "## A. Pattern Matching Labeling Functions\n",
    "\n",
    "One powerful form of labeling function design is defining sets of keywords or regular expressions that, as a human labeler, you know are correlated with the true label. In the terminology of [Bayesian inference](https://en.wikipedia.org/wiki/Statistical_inference#Bayesian_inference), this can be thought of as defining a [_prior_](https://en.wikipedia.org/wiki/Prior_probability) over your word features. \n",
    "\n",
    "For example, we could define a dictionary of terms that occur between person names in a candidate. One simple dictionary of terms indicating a true relation could be:\n",
    "    \n",
    "    marriage = {'husband', 'wife'}\n",
    " \n",
    "We can then write a labeling function that checks for a match with these terms in the text that occurs between person names.\n",
    "\n",
    "    def LF_marriage_terms_between(c):\n",
    "        return 1 if len(marriage.intersection(get_between_tokens(c))) > 0 else 0\n",
    "        \n",
    "The idea is that we can easily create dictionaries that encode themes or categories descibing all kinds of relationships between 2 people and then use these objects to _weakly supervise_ our classification task.\n",
    "\n",
    "    other_relationship = {'boyfriend', 'girlfriend'}\n",
    "    \n",
    "**IMPORTANT** Good labeling functions manage a trade-off between high coverage and high precision. When constructing your dictionaries, think about building larger, noiser sets of terms instead of relying on 1 or 2 keywords. Sometimes a single word can be very predictive (e.g., `ex-wife`) but it's almost always better to define something more general, such as a regular expression pattern capturing _any_ string with the `ex-` prefix. \n",
    "    \n",
    "\n",
    "### 1. Labeling Function Factories\n",
    "The above is a reasonable way to write labeling functions. However, this type of design pattern is so common that we rely on another abstraction to help us build LFs more quickly: _labeling function factories_. Factories accept simple inputs, like dictionaries or a set of regular expressions, and automatically builds labeling functions for you.\n",
    "\n",
    "The `MatchTerms` and `MatchRegex` factories require a few parameter definitions to setup:\n",
    "    \n",
    "    name:    a string that describes the category of terms/regular expressons\n",
    "    label:   patterns correlate with a True or False label (1 or -1) \n",
    "    search:  search a specific part of the sentence ('left'|'right'|'between'|'sentence')\n",
    "    window:  the length of tokens to match against for ('left'|'right') search spaces \n",
    "\n",
    "### 2. Term Matching Factory\n",
    "We illustrate below how you can use the `MatchTerms` factory to create and test an LF on training candidates. When examining candidates in the `SentenceNgramViewer`, notice that husband or wife always occurs between person names. That is the supervision signal encoded by this LF!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "marriage  = {'husband', 'wife'}\n",
    "\n",
    "# we'll initialize our LFG and test its coverage on training candidates\n",
    "LF_marriage = MatchTerms(name='marriage', terms=marriage, label=1, search='between').lf()\n",
    "\n",
    "# what candidates are covered by this LF?\n",
    "labeled = coverage(session, LF_marriage, split=0)\n",
    "\n",
    "# now let's view what this LF labeled\n",
    "SentenceNgramViewer(labeled, session, n_per_page=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing Error Buckets\n",
    "If we have gold labeled data, we can evaluate formal metrics. It's useful to view specific errors for a given LF input in the `SentenceNgramViewer`.\n",
    "\n",
    "Below, we'll compute our empirical scores using human-labeled development set data and then look at any false positive matches by our `LF_marriage` LF. We can see below from our scores that this LF isn't very accurate -- only 36% precision!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tp, fp, tn, fn = error_analysis(session, LF_marriage, split=1, gold=L_gold_dev)\n",
    "\n",
    "# now let's view what this LF labeled\n",
    "SentenceNgramViewer(fp, session, n_per_page=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Search Contexts\n",
    "We can also search other sentence contexts, such as a window of text to the left or right of our candidate spans. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "other_relationship  = {'boyfriend', 'girlfriend'}\n",
    "\n",
    "LF_other_relationship = MatchTerms(name='other_relationship', terms=other_relationship, \n",
    "                                   label=-1, search='left', window=1).lf()\n",
    "labeled = coverage(session, LF_other_relationship, split=1)\n",
    "\n",
    "# now let's view what this LF labeled\n",
    "SentenceNgramViewer(labeled, session, n_per_page=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Regular Expression Factory\n",
    "\n",
    "Sometimes we want to express more generic textual patterns to match against candidates. Perhaps we want to match a specific phrase like 'power couple' or look for modifier prefixes like 'ex' wife, husband, etc. \n",
    "\n",
    "We can generate this supervision in the same way as above using sets of [regular expressions](https://en.wikipedia.org/wiki/Regular_expression) -- a formal language for string matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exes_rgxs = {' ex[- ](husband|wife)'}\n",
    "\n",
    "LF_exes = MatchRegex(name='exes', rgxs=exes_rgxs, label=-1, search='between').lf()\n",
    "labeled = coverage(session, LF_exes, split=1)\n",
    "\n",
    "# now let's view what this LF labeled\n",
    "SentenceNgramViewer(labeled, session, n_per_page=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Distant Supervision Labeling Functions\n",
    "\n",
    "In addition to using factories that encode pattern matching heuristics, we can also write labeling functions that _distantly supervise_ examples. Here, we'll load in a list of known spouse pairs and check to see if the candidate pair matches one of these.\n",
    "\n",
    "**DBpedia**\n",
    "http://wiki.dbpedia.org/\n",
    "Out database of known spouses comes from DBpedia, which is a community-driven resource similar to Wikipedia but for curating structured data. We'll use a preprocessed snapshot as our knowledge base for all labeling function development.\n",
    "\n",
    "We can look at some of the example entries from DBPedia and use them in a simple distant supervision labeling function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lib.dbpedia import known_spouses \n",
    "\n",
    "list(known_spouses)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LF_distant_supervision = DistantSupervision(\"dbpedia\", kb=known_spouses).lf()\n",
    "labeled = coverage(session, LF_distant_supervision, split=1)\n",
    "\n",
    "# score out LF against dev set labels\n",
    "score(session, LF_distant_supervision, split=1, gold=L_gold_dev)\n",
    "\n",
    "SentenceNgramViewer(labeled, session, n_per_page=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Writing Custom Labeling Functions\n",
    "\n",
    "The strength of LFs is that you can write any arbitrary function and use it to supervise a classification task. This approach can combine many of the same strategies discussed above or encode other information. \n",
    "\n",
    "For example, we observe that when mentions of person names occur far apart in a sentence, this is a good indicator that the candidate's label is False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LF_too_far_apart(c):\n",
    "    \"\"\"Person mentions occur at a distance > 50 words\"\"\"\n",
    "    return -1 if len(list(get_between_tokens(c))) > 50 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "labeled = coverage(session, LF_too_far_apart, split=1)\n",
    "score(session, LF_too_far_apart, split=1, gold=L_gold_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Composing Labeling Functions\n",
    "\n",
    "Another useful technique for writing LFs is composing multiple, weaker LFs together. For example, our `LF_marriage` example above has low precision.  Instead of modifying `LF_marriage`, we'll compose it with our `LF_too_far_apart` from above.\n",
    "\n",
    "    LF_marriage                                TP: 61 | FP: 109\n",
    "    LF_marriage AND NOT LF_too_far_apart       TP: 58 | FP: 82\n",
    "    \n",
    "We missed 3 true candidates, but we cut our false positive rate by 27 candidates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LF_marriage_and_not_same_person(c):\n",
    "    return 1 if LF_too_far_apart(c) != -1 and LF_marriage(c) == 1 else 0\n",
    "\n",
    "LF_marriage_and_not_same_person = lambda c: LF_too_far_apart(c) != -1 and LF_marriage(c)\n",
    "\n",
    "score(session, LF_marriage_and_not_same_person, split=1, gold=L_gold_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI. Development Sandbox\n",
    "----\n",
    "\n",
    "## A. Writing Your Own Labeling Functions\n",
    "\n",
    "Using the information above, write your own labeling functions for this task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# PLACE YOUR LFs HERE\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Applying Labeling Functions\n",
    "---\n",
    "\n",
    "Next, we need to actually run the LFs over **all** of our training candidates, producing a set of `Labels` and `LabelKeys` (just the names of the LFs) in the database.  We'll do this using the `LabelAnnotator` class, a UDF which we will again run with `UDFRunner`.\n",
    "\n",
    "### 1. Preparing your Labeling Functions\n",
    "\n",
    "First we put all our labeling functions into list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LFs = [\n",
    "    \n",
    "    # place your lf function variable names here\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we setup the label annotator class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelAnnotator\n",
    "labeler = LabelAnnotator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generating the Label Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1701)\n",
    "\n",
    "%time L_train = labeler.apply(split=0, lfs=LFs, parallelism=1)\n",
    "print L_train.shape\n",
    "\n",
    "%time L_dev = labeler.apply_existing(split=1, lfs=LFs, parallelism=1)\n",
    "print L_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_train.lf_stats(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Label Matrix Empirical Accuracies\n",
    "\n",
    "If we have a small set of human-labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_dev.lf_stats(session, labels=L_gold_dev.toarray().ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Iterating on Labeling Function Design\n",
    "\n",
    "When writing labeling functions, you will want to iterate on the process outlined above several times. You should focus on tuning individual LFs, based on emprical accuracy metrics, and adding new LFs to improve coverage. "
   ]
  }
 ],
 "metadata": {
  "anaconda-butt": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
